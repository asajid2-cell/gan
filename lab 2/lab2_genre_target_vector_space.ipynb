{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Genre Target Vector Space\n",
    "\n",
    "This notebook finalizes Lab 2 as a reproducible calibration pipeline on top of the frozen Lab 1 encoder.\n",
    "\n",
    "What this notebook does:\n",
    "1. Materialize and/or reuse genre samples.\n",
    "2. Harvest (or reload) embeddings from the frozen Lab 1 model.\n",
    "3. Build weighted target vectors, optionally apply supervised LDA warp.\n",
    "4. Build purified centroids (top-k inlier fraction).\n",
    "5. Run full Lab 2 exit audit and export all artifacts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Resume Contract\n",
    "\n",
    "This notebook supports the same practical run behavior as your scripts:\n",
    "- `RUN_MODE='fresh'`: create a new run folder under `saves/lab2_calibration`.\n",
    "- `RUN_MODE='resume'`: continue from an existing run folder without recomputing completed stages.\n",
    "- Stage outputs are persisted after each stage.\n",
    "- `run_state.json` tracks progress, config, and final pass/fail status.\n",
    "\n",
    "You can also bootstrap from a previous run by setting `REUSE_ARTIFACTS_DIR`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.lab2_data import load_manifests, assign_genres, materialize_genre_samples, genre_count_table\n",
    "from src.lab2_encoder_bridge import FrozenLab1Encoder\n",
    "from src.lab2_pipeline import (\n",
    "    harvest_embeddings,\n",
    "    compose_target_space,\n",
    "    apply_lda_projection,\n",
    "    compute_centroids,\n",
    "    compute_centroid_distances,\n",
    "    validate_target_space,\n",
    "    write_artifacts,\n",
    "    run_exit_audit,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Run Controls\n",
    "# -----------------------------\n",
    "REPO_ROOT = Path.cwd().parent\n",
    "OUTPUT_ROOT = REPO_ROOT / 'saves' / 'lab2_calibration'\n",
    "\n",
    "RUN_MODE = 'fresh'          # 'fresh' or 'resume'\n",
    "RUN_TAG = ''                # optional custom folder name for fresh mode\n",
    "RESUME_ARTIFACTS_DIR = None # required only when RUN_MODE='resume', e.g. REPO_ROOT / 'saves/lab2_calibration/lab2_...'\n",
    "\n",
    "# Optional bootstrap from another run's embeddings (skips Stage 1/2 extraction)\n",
    "REUSE_ARTIFACTS_DIR = None  # e.g. REPO_ROOT / 'saves/lab2_calibration/lab2_20260211_015118'\n",
    "\n",
    "# Stage toggles\n",
    "RUN_STAGE1 = True\n",
    "RUN_STAGE2 = True\n",
    "RUN_STAGE3 = True\n",
    "\n",
    "# Data + model\n",
    "MANIFESTS_ROOT = Path('Z:/DataSets/_lab1_manifests')\n",
    "CHECKPOINT = REPO_ROOT / 'saves/lab1_run_combo_af_gate_exit_v2/latest.pt'\n",
    "PER_GENRE_SAMPLES = 1200\n",
    "SEED = 328\n",
    "DEVICE = 'auto'\n",
    "\n",
    "# Calibration knobs\n",
    "PROJECTION = 'lda'          # 'raw' or 'lda'\n",
    "ZSTYLE_WEIGHT = 2.0\n",
    "DESCRIPTOR_WEIGHT = 1.0\n",
    "CENTROID_INLIER_FRACTION = 0.5\n",
    "AUDIT_INLIER_FRACTION = 0.5\n",
    "\n",
    "# Exit thresholds\n",
    "SILHOUETTE_THRESHOLD = 0.45\n",
    "SIGMA_MULTIPLIER = 3.0\n",
    "NEIGHBOR_TOP_K = 5\n",
    "NEIGHBOR_MIN_MEAN_HITS = 4.0\n",
    "STABILITY_SAMPLE_FRACTION = 0.2\n",
    "STABILITY_TRIALS = 10\n",
    "TSNE_MAX_POINTS = 5000\n",
    "\n",
    "if RUN_MODE == 'fresh':\n",
    "    ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    folder = RUN_TAG if RUN_TAG else f'lab2_nb_{ts}'\n",
    "    OUT_DIR = OUTPUT_ROOT / folder\n",
    "elif RUN_MODE == 'resume':\n",
    "    if RESUME_ARTIFACTS_DIR is None:\n",
    "        raise ValueError(\"RUN_MODE='resume' requires RESUME_ARTIFACTS_DIR\")\n",
    "    OUT_DIR = Path(RESUME_ARTIFACTS_DIR)\n",
    "else:\n",
    "    raise ValueError(\"RUN_MODE must be 'fresh' or 'resume'\")\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Run-State Helpers\n",
    "# -----------------------------\n",
    "state_path = OUT_DIR / 'run_state.json'\n",
    "\n",
    "\n",
    "def _save_json(obj, path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with path.open('w', encoding='utf-8') as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "\n",
    "def _load_json(path: Path, default=None):\n",
    "    if path.exists():\n",
    "        with path.open('r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    return {} if default is None else default\n",
    "\n",
    "\n",
    "def _save_embeddings(out_dir: Path, index_df: pd.DataFrame, arrays: dict):\n",
    "    index_df.to_csv(out_dir / 'embeddings_index.csv', index=False)\n",
    "    np.savez_compressed(\n",
    "        out_dir / 'embeddings.npz',\n",
    "        z_content=arrays['z_content'],\n",
    "        z_style=arrays['z_style'],\n",
    "        descriptor32=arrays['descriptor32'],\n",
    "        target160=arrays['target160'],\n",
    "        music_prob=arrays['music_prob'],\n",
    "    )\n",
    "\n",
    "\n",
    "def _load_embeddings(out_dir: Path):\n",
    "    idx_path = out_dir / 'embeddings_index.csv'\n",
    "    npz_path = out_dir / 'embeddings.npz'\n",
    "    if not idx_path.exists() or not npz_path.exists():\n",
    "        return None, None\n",
    "    index_df = pd.read_csv(idx_path)\n",
    "    z = np.load(npz_path)\n",
    "    arrays = {\n",
    "        'z_content': z['z_content'].astype(np.float32),\n",
    "        'z_style': z['z_style'].astype(np.float32),\n",
    "        'descriptor32': z['descriptor32'].astype(np.float32),\n",
    "        'target160': z['target160'].astype(np.float32),\n",
    "        'music_prob': z['music_prob'].astype(np.float32),\n",
    "    }\n",
    "    return index_df, arrays\n",
    "\n",
    "\n",
    "state = _load_json(state_path, default={\n",
    "    'stage1_done': False,\n",
    "    'stage2_done': False,\n",
    "    'stage3_done': False,\n",
    "    'created_at': datetime.now().isoformat(timespec='seconds'),\n",
    "})\n",
    "\n",
    "state['config'] = {\n",
    "    'run_mode': RUN_MODE,\n",
    "    'out_dir': str(OUT_DIR),\n",
    "    'reuse_artifacts_dir': str(REUSE_ARTIFACTS_DIR) if REUSE_ARTIFACTS_DIR else '',\n",
    "    'checkpoint': str(CHECKPOINT),\n",
    "    'projection': PROJECTION,\n",
    "    'zstyle_weight': float(ZSTYLE_WEIGHT),\n",
    "    'descriptor_weight': float(DESCRIPTOR_WEIGHT),\n",
    "    'centroid_inlier_fraction': float(CENTROID_INLIER_FRACTION),\n",
    "    'audit_inlier_fraction': float(AUDIT_INLIER_FRACTION),\n",
    "    'silhouette_threshold': float(SILHOUETTE_THRESHOLD),\n",
    "    'sigma_multiplier': float(SIGMA_MULTIPLIER),\n",
    "    'neighbor_top_k': int(NEIGHBOR_TOP_K),\n",
    "    'neighbor_min_mean_hits': float(NEIGHBOR_MIN_MEAN_HITS),\n",
    "}\n",
    "\n",
    "_save_json(state, state_path)\n",
    "state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Genre Materialization\n",
    "\n",
    "Goal: create a balanced, explicit sample manifest for this run.\n",
    "\n",
    "Resume behavior:\n",
    "- If `genre_samples.csv` already exists in `OUT_DIR`, it is loaded.\n",
    "- Otherwise it is generated from manifests and saved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_samples_path = OUT_DIR / 'genre_samples.csv'\n",
    "\n",
    "if genre_samples_path.exists():\n",
    "    samples_df = pd.read_csv(genre_samples_path)\n",
    "    assigned_counts = state.get('assigned_genre_counts', {})\n",
    "    sampled_counts = genre_count_table(samples_df)\n",
    "    print('[stage1] loaded existing genre_samples.csv')\n",
    "else:\n",
    "    if not RUN_STAGE1:\n",
    "        raise RuntimeError('Stage 1 is disabled but no saved genre_samples.csv was found.')\n",
    "\n",
    "    raw_df = load_manifests(MANIFESTS_ROOT)\n",
    "    assigned_df = assign_genres(raw_df)\n",
    "    assigned_counts = genre_count_table(assigned_df)\n",
    "\n",
    "    samples_df = materialize_genre_samples(\n",
    "        assigned_df,\n",
    "        per_genre_samples=PER_GENRE_SAMPLES,\n",
    "        seed=SEED,\n",
    "    )\n",
    "    sampled_counts = genre_count_table(samples_df)\n",
    "    samples_df.to_csv(genre_samples_path, index=False)\n",
    "    print('[stage1] created and saved genre_samples.csv')\n",
    "\n",
    "state['assigned_genre_counts'] = assigned_counts\n",
    "state['sampled_genre_counts'] = sampled_counts\n",
    "state['stage1_done'] = True\n",
    "_save_json(state, state_path)\n",
    "\n",
    "print('Assigned counts:', assigned_counts)\n",
    "print('Sampled counts:', sampled_counts)\n",
    "samples_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Embedding Harvest (or Reload)\n",
    "\n",
    "Goal: produce stable embedding artifacts (`embeddings_index.csv`, `embeddings.npz`).\n",
    "\n",
    "Resume behavior:\n",
    "- If embeddings already exist in `OUT_DIR`, they are loaded.\n",
    "- If `REUSE_ARTIFACTS_DIR` is set, embeddings are loaded from there.\n",
    "- Otherwise embeddings are harvested from the frozen Lab 1 encoder.\n",
    "\n",
    "After load/harvest, weighted target composition and optional LDA warp are applied,\n",
    "and the resulting vectors are saved back into this run folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_df, arrays = _load_embeddings(OUT_DIR)\n",
    "\n",
    "if index_df is not None and arrays is not None:\n",
    "    print('[stage2] loaded embeddings from current OUT_DIR')\n",
    "else:\n",
    "    if REUSE_ARTIFACTS_DIR is not None:\n",
    "        reuse_dir = Path(REUSE_ARTIFACTS_DIR)\n",
    "        index_df, arrays = _load_embeddings(reuse_dir)\n",
    "        if index_df is None:\n",
    "            raise FileNotFoundError(f'No embeddings found in REUSE_ARTIFACTS_DIR: {reuse_dir}')\n",
    "        print(f'[stage2] loaded embeddings from REUSE_ARTIFACTS_DIR: {reuse_dir}')\n",
    "    else:\n",
    "        if not RUN_STAGE2:\n",
    "            raise RuntimeError('Stage 2 is disabled and no cached embeddings were found.')\n",
    "        encoder = FrozenLab1Encoder(CHECKPOINT, device=DEVICE)\n",
    "        index_df, arrays = harvest_embeddings(samples_df, encoder, progress_every=100)\n",
    "        print('[stage2] harvested embeddings using frozen Lab 1 checkpoint')\n",
    "\n",
    "# Compose weighted target space from z_style + descriptor block\n",
    "arrays['target160'] = compose_target_space(\n",
    "    arrays=arrays,\n",
    "    zstyle_weight=ZSTYLE_WEIGHT,\n",
    "    descriptor_weight=DESCRIPTOR_WEIGHT,\n",
    "    normalize_rows=True,\n",
    ")\n",
    "\n",
    "projection_meta = {\n",
    "    'projection': 'raw',\n",
    "    'input_dim': int(arrays['target160'].shape[1]),\n",
    "    'output_dim': int(arrays['target160'].shape[1]),\n",
    "}\n",
    "\n",
    "if PROJECTION == 'lda':\n",
    "    X_proj, projection_meta = apply_lda_projection(index_df=index_df, arrays=arrays, seed=SEED)\n",
    "    arrays['target160'] = X_proj\n",
    "    print('[stage2] applied supervised LDA projection')\n",
    "\n",
    "_save_embeddings(OUT_DIR, index_df, arrays)\n",
    "_save_json(projection_meta, OUT_DIR / 'projection_meta.json')\n",
    "\n",
    "state['stage2_done'] = True\n",
    "state['n_samples'] = int(len(index_df))\n",
    "state['target_dim'] = int(arrays['target160'].shape[1])\n",
    "state['projection_meta'] = projection_meta\n",
    "_save_json(state, state_path)\n",
    "\n",
    "print('n_samples:', len(index_df), 'target_dim:', arrays['target160'].shape[1])\n",
    "index_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Centroids, Exit Audit, and Final Artifacts\n",
    "\n",
    "Goal: compute centroids and run the official Lab 2 exit checklist.\n",
    "\n",
    "This stage writes:\n",
    "- `validation_summary.json`\n",
    "- `target_centroids.json`\n",
    "- `lab2_exit_checklist.json`\n",
    "- `neighbor_audit.csv`, `inter_centroid_separation.csv`, `global_genre_map_tsne.png`, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RUN_STAGE3:\n",
    "    raise RuntimeError('Stage 3 is disabled for this run.')\n",
    "\n",
    "centroids_df = compute_centroids(\n",
    "    index_df=index_df,\n",
    "    target160=arrays['target160'],\n",
    "    inlier_fraction=CENTROID_INLIER_FRACTION,\n",
    "    inlier_metric='cosine',\n",
    ")\n",
    "centroid_distances_df = compute_centroid_distances(centroids_df)\n",
    "summary = validate_target_space(index_df, arrays, seed=SEED)\n",
    "\n",
    "summary['config'] = {\n",
    "    'checkpoint': str(CHECKPOINT),\n",
    "    'manifests_root': str(MANIFESTS_ROOT),\n",
    "    'per_genre_samples': int(PER_GENRE_SAMPLES),\n",
    "    'seed': int(SEED),\n",
    "    'device': str(DEVICE),\n",
    "    'projection': str(PROJECTION),\n",
    "    'zstyle_weight': float(ZSTYLE_WEIGHT),\n",
    "    'descriptor_weight': float(DESCRIPTOR_WEIGHT),\n",
    "    'centroid_inlier_fraction': float(CENTROID_INLIER_FRACTION),\n",
    "    'audit_inlier_fraction': float(AUDIT_INLIER_FRACTION),\n",
    "    'neighbor_min_mean_hits': float(NEIGHBOR_MIN_MEAN_HITS),\n",
    "}\n",
    "summary['assigned_genre_counts'] = assigned_counts\n",
    "summary['sampled_genre_counts'] = sampled_counts\n",
    "summary['projection_meta'] = projection_meta\n",
    "\n",
    "write_artifacts(\n",
    "    output_dir=OUT_DIR,\n",
    "    index_df=index_df,\n",
    "    arrays=arrays,\n",
    "    centroids_df=centroids_df,\n",
    "    centroid_distances_df=centroid_distances_df,\n",
    "    validation_summary=summary,\n",
    ")\n",
    "\n",
    "exit_checklist = run_exit_audit(\n",
    "    output_dir=OUT_DIR,\n",
    "    index_df=index_df,\n",
    "    arrays=arrays,\n",
    "    centroids_df=centroids_df,\n",
    "    centroid_distances_df=centroid_distances_df,\n",
    "    validation_summary=summary,\n",
    "    silhouette_threshold=SILHOUETTE_THRESHOLD,\n",
    "    sigma_multiplier=SIGMA_MULTIPLIER,\n",
    "    neighbor_top_k=NEIGHBOR_TOP_K,\n",
    "    neighbor_min_mean_hits=NEIGHBOR_MIN_MEAN_HITS,\n",
    "    audit_inlier_fraction=AUDIT_INLIER_FRACTION,\n",
    "    stability_sample_fraction=STABILITY_SAMPLE_FRACTION,\n",
    "    stability_trials=STABILITY_TRIALS,\n",
    "    tsne_max_points=TSNE_MAX_POINTS,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "state['stage3_done'] = True\n",
    "state['lab2_done'] = bool(exit_checklist.get('lab2_done', False))\n",
    "state['finished_at'] = datetime.now().isoformat(timespec='seconds')\n",
    "state['key_metrics'] = summary.get('metrics', {})\n",
    "state['exit_summary'] = exit_checklist\n",
    "_save_json(state, state_path)\n",
    "\n",
    "exit_checklist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Snapshot\n",
    "\n",
    "Use this cell for quick reporting and sanity checks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick = {\n",
    "    'out_dir': str(OUT_DIR),\n",
    "    'lab2_done': bool(state.get('lab2_done', False)),\n",
    "    'metrics': state.get('key_metrics', {}),\n",
    "    'assigned_genre_counts': state.get('assigned_genre_counts', {}),\n",
    "    'sampled_genre_counts': state.get('sampled_genre_counts', {}),\n",
    "}\n",
    "quick\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}