{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "29a58003",
      "metadata": {},
      "source": [
        "# Lab 3 - Reconstruction Decoder (Notebook Runner)\n",
        "\n",
        "This notebook is configured to run Lab 3 end-to-end from top to bottom:\n",
        "\n",
        "1. Configure run variables (single config cell).\n",
        "2. Launch staged training (`stage1` then `stage2`) using `run_lab3.py`.\n",
        "3. Load audit outputs.\n",
        "4. Generate qualitative samples (mel plots + WAV files) for direct inspection.\n",
        "\n",
        "Use `RUN_MODE='fresh'` for a new run or `RUN_MODE='resume'` to continue an existing run.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56fa67b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "import shutil\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    import soundfile as sf\n",
        "    HAS_SF = True\n",
        "except Exception:\n",
        "    HAS_SF = False\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "from src.lab3_data import load_cache, stratified_split_indices\n",
        "from src.lab3_models import ReconstructionDecoder\n",
        "from src.lab3_bridge import FrozenLab1Encoder, denormalize_log_mel\n",
        "from src.lab3_train import load_target_centroids, build_condition_bank\n",
        "from src.lab3_sampling import export_posttrain_samples\n",
        "import importlib\n",
        "\n",
        "# torch sanity guard for notebook kernels with partially initialized modules\n",
        "if not hasattr(torch, '_utils'):\n",
        "    torch._utils = importlib.import_module('torch._utils')\n",
        "print('torch:', torch.__version__, 'file:', torch.__file__)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dc4a15d",
      "metadata": {},
      "source": [
        "## Run Config\n",
        "\n",
        "Set everything here, then run all cells.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dfe62f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Core run controls\n",
        "# -----------------------------\n",
        "REPO_ROOT = Path.cwd().parent\n",
        "LAB3_DIR = Path.cwd()\n",
        "SAVES_ROOT = REPO_ROOT / 'saves2' / 'lab3_synthesis'\n",
        "\n",
        "def find_latest_run_dir(saves_root: Path):\n",
        "    candidates = []\n",
        "    for d in saves_root.iterdir() if saves_root.exists() else []:\n",
        "        if not d.is_dir():\n",
        "            continue\n",
        "        rs = d / 'run_state.json'\n",
        "        if rs.exists():\n",
        "            candidates.append(d)\n",
        "    if not candidates:\n",
        "        return None\n",
        "    return max(candidates, key=lambda p: (p / 'run_state.json').stat().st_mtime)\n",
        "\n",
        "RUN_MODE = 'fresh'  # 'fresh' or 'resume'\n",
        "RUN_NAME = ''               # empty => strict auto numbered folders: run1, run2, ...\n",
        "RESUME_DIR = SAVES_ROOT / 'run1'  # used only when RUN_MODE='resume'\n",
        "CLEAN_START = False          # if fresh and run folder exists, delete it first\n",
        "\n",
        "# Optional cache reuse (speeds up iteration)\n",
        "REUSE_CACHE_DIR = None  # resume from run cache/checkpoints\n",
        "\n",
        "# -----------------------------\n",
        "# Data/model paths\n",
        "# -----------------------------\n",
        "MANIFESTS_ROOT = Path('Z:/DataSets/_lab1_manifests')\n",
        "LAB1_CHECKPOINT = REPO_ROOT / 'saves' / 'lab1_run_combo_af_gate_exit_v2' / 'latest.pt'\n",
        "LAB2_TARGET_CENTROIDS = REPO_ROOT / 'saves' / 'lab2_calibration' / 'lab2_20260211_015118_lda_cleanup_v2' / 'target_centroids.json'\n",
        "\n",
        "# -----------------------------\n",
        "# Training scale\n",
        "# -----------------------------\n",
        "SMOKE = False\n",
        "PER_GENRE_SAMPLES = 800\n",
        "CHUNKS_PER_TRACK = 4\n",
        "CHUNK_SAMPLING = 'uniform'\n",
        "MIN_START_SEC = 0.0\n",
        "MAX_START_SEC = None\n",
        "SPLIT_BY_TRACK = True\n",
        "STAGE2_COND_MODE = 'mix'\n",
        "STAGE2_COND_ALPHA_START = 0.8\n",
        "STAGE2_COND_ALPHA_END = 0.4\n",
        "STAGE2_COND_EXEMPLAR_NOISE_STD = 0.03\n",
        "STAGE2_TARGET_BALANCE = True\n",
        "VAL_RATIO = 0.15\n",
        "N_FRAMES = 256\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 0\n",
        "SEED = 328\n",
        "DEVICE = 'auto'              # 'auto' | 'cuda' | 'cpu'\n",
        "GENERATOR_NORM = 'instance'  # 'instance' | 'batch'\n",
        "GENERATOR_SPECTRAL_NORM = False\n",
        "GENERATOR_UPSAMPLE = 'transpose'  # 'transpose' | 'pixelshuffle'\n",
        "DISCRIMINATOR_ARCH = 'single'  # 'single' | 'multiscale'\n",
        "DISCRIMINATOR_SCALES = 3\n",
        "\n",
        "STAGE1_EPOCHS = 20\n",
        "STAGE2_EPOCHS = 60\n",
        "MAX_BATCHES_PER_EPOCH = None # int or None\n",
        "\n",
        "# -----------------------------\n",
        "# Loss weights\n",
        "# -----------------------------\n",
        "LR_G = 2e-4\n",
        "LR_D = 2e-4\n",
        "ADV_WEIGHT = 0.8\n",
        "RECON_WEIGHT = 8.0\n",
        "CONTENT_WEIGHT = 3.0\n",
        "STYLE_WEIGHT = 10.0\n",
        "CONTINUITY_WEIGHT = 1.0\n",
        "MRSTFT_WEIGHT = 0.0\n",
        "STAGE1_MRSTFT_WEIGHT = 0.0\n",
        "STAGE2_MRSTFT_WEIGHT = 0.0\n",
        "MRSTFT_RESOLUTIONS = '64,16,64;128,32,128;256,64,256'\n",
        "FLATNESS_WEIGHT = 0.2\n",
        "FEATURE_MATCH_WEIGHT = 0.0\n",
        "PERCEPTUAL_WEIGHT = 0.0\n",
        "STYLE_HINGE_WEIGHT = 0.0\n",
        "CONTRASTIVE_WEIGHT = 0.0\n",
        "BATCH_INFONCE_DIV_WEIGHT = 0.0\n",
        "DIVERSITY_WEIGHT = 0.0\n",
        "TIMBRE_BALANCE_WEIGHT = 0.0\n",
        "LOWMID_RECON_WEIGHT = 0.0\n",
        "SPECTRAL_TILT_WEIGHT = 0.0\n",
        "ZCR_PROXY_WEIGHT = 0.0\n",
        "STYLE_MID_WEIGHT = 0.0\n",
        "HF_MUZZLE_WEIGHT = 0.0\n",
        "HIGHPASS_ANCHOR_WEIGHT = 0.0\n",
        "MEL_DIVERSITY_WEIGHT = 0.0\n",
        "TARGET_PROFILE_WEIGHT = 0.0\n",
        "STAGE2_D_LR_MULT = 0.5\n",
        "STAGE2_CONTENT_START = 0.5\n",
        "STAGE2_CONTENT_END = 0.2\n",
        "STAGE2_STYLE_LABEL_SMOOTHING = 0.1\n",
        "STAGE2_STYLE_ONLY_WARMUP_EPOCHS = 4\n",
        "STAGE2_G_LR_WARMUP_EPOCHS = 5\n",
        "STAGE2_G_LR_START_MULT = 0.3\n",
        "STAGE2_COND_NOISE_STD = 0.0\n",
        "STAGE2_STYLE_JITTER_STD = 0.0\n",
        "STAGE2_STYLE_HINGE_TARGET_CONF = 0.85\n",
        "STAGE2_ADAPTIVE_CONTENT = False\n",
        "STAGE2_ADAPTIVE_CONTENT_LOW = 0.0\n",
        "STAGE2_ADAPTIVE_CONTENT_HIGH = 0.4\n",
        "STAGE2_ADAPTIVE_CONF_LOW = 0.30\n",
        "STAGE2_ADAPTIVE_CONF_HIGH = 0.45\n",
        "STAGE2_STYLE_CRITIC_LR = 2e-4\n",
        "STAGE2_CONTRASTIVE_TEMP = 0.10\n",
        "STAGE2_BATCH_INFONCE_TEMP = 0.15\n",
        "STAGE2_DIVERSITY_MARGIN = 0.90\n",
        "STAGE2_DIVERSITY_MAX_PAIRS = 128\n",
        "STAGE2_MEL_DIVERSITY_MARGIN = 0.60\n",
        "STAGE2_MEL_DIVERSITY_MAX_PAIRS = 192\n",
        "STAGE2_STYLE_LOWPASS_KEEP_BINS = 80\n",
        "STAGE2_STYLE_LOWPASS_CUTOFF_HZ = None\n",
        "STAGE2_STYLE_MID_LOW_BIN = 8\n",
        "STAGE2_STYLE_MID_HIGH_BIN = 56\n",
        "STAGE2_LOWMID_SPLIT_BIN = 80\n",
        "STAGE2_LOWMID_GAIN = 7.0\n",
        "STAGE2_HIGH_GAIN = 0.45\n",
        "STAGE2_SPECTRAL_TILT_MAX_RATIO = 0.78\n",
        "STAGE2_ZCR_PROXY_TARGET_MAX = 0.20\n",
        "STAGE2_STYLE_THAW_LAST_EPOCHS = 0\n",
        "STAGE2_STYLE_THAW_LR = 1e-6\n",
        "STAGE2_STYLE_THAW_SCOPE = 'style_head'\n",
        "RESET_STAGE2_OUT_LAYER = False\n",
        "D_REAL_LABEL = 1.0\n",
        "D_FAKE_LABEL = 0.0\n",
        "G_REAL_LABEL = 1.0\n",
        "\n",
        "# -----------------------------\n",
        "# Exit thresholds\n",
        "# -----------------------------\n",
        "MPS_THRESHOLD = 0.90\n",
        "SF_THRESHOLD = 0.85\n",
        "EVAL_MAX_BATCHES = 30\n",
        "\n",
        "# -----------------------------\n",
        "# Generation preview settings\n",
        "# -----------------------------\n",
        "N_GENERATION_SAMPLES = 6\n",
        "TARGET_GENRE_ORDER = ['baroque_classical', 'hiphop_xtc', 'lofi_hh_lfbb', 'cc0_other']\n",
        "POSTTRAIN_SAMPLE_EXPORT_TAG = 'posttrain_samples'\n",
        "POSTTRAIN_SAMPLE_COUNT = 100\n",
        "POSTTRAIN_SAMPLE_TARGET_MODE = 'balanced_random'\n",
        "POSTTRAIN_SAMPLE_WRITE_REAL = True\n",
        "GL_ITERS = 64\n",
        "\n",
        "if RUN_MODE == 'fresh':\n",
        "    OUT_DIR = SAVES_ROOT / RUN_NAME if RUN_NAME else SAVES_ROOT\n",
        "elif RUN_MODE == 'resume':\n",
        "    if RESUME_DIR is None:\n",
        "        raise ValueError(\"RUN_MODE='resume' requires RESUME_DIR\")\n",
        "    OUT_DIR = Path(RESUME_DIR)\n",
        "else:\n",
        "    raise ValueError(\"RUN_MODE must be 'fresh' or 'resume'\")\n",
        "\n",
        "OUT_DIR\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02b04309",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare run directory (fresh mode cleanup)\n",
        "if RUN_MODE == 'fresh' and RUN_NAME == '':\n",
        "    print('[setup] RUN_NAME empty: training will auto-create numbered run directories (run1, run2, ...).')\n",
        "\n",
        "if RUN_MODE == 'fresh' and CLEAN_START and RUN_NAME and OUT_DIR.exists():\n",
        "    print(f'[setup] removing existing run dir: {OUT_DIR}')\n",
        "    shutil.rmtree(OUT_DIR)\n",
        "\n",
        "if RUN_MODE == 'resume':\n",
        "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print('[setup] target run_dir =', OUT_DIR)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab200a58",
      "metadata": {},
      "source": [
        "## Launch Training Pipeline\n",
        "\n",
        "This calls `run_lab3.py` with the config above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bd78882",
      "metadata": {},
      "outputs": [],
      "source": [
        "cmd = [\n",
        "    'python', 'run_lab3.py',\n",
        "    '--mode', RUN_MODE,\n",
        "    '--out-root', str(SAVES_ROOT),\n",
        "    '--strict-run-naming',\n",
        "    '--manifests-root', str(MANIFESTS_ROOT),\n",
        "    '--lab1-checkpoint', str(LAB1_CHECKPOINT),\n",
        "    '--lab2-centroids-json', str(LAB2_TARGET_CENTROIDS),\n",
        "    '--per-genre-samples', str(PER_GENRE_SAMPLES),\n",
        "    '--chunks-per-track', str(CHUNKS_PER_TRACK),\n",
        "    '--chunk-sampling', str(CHUNK_SAMPLING),\n",
        "    '--min-start-sec', str(MIN_START_SEC),\n",
        "    '--max-start-sec', str(MAX_START_SEC) if MAX_START_SEC is not None else '',\n",
        "    '--split-by-track' if SPLIT_BY_TRACK else '--no-split-by-track',\n",
        "    '--seed', str(SEED),\n",
        "    '--val-ratio', str(VAL_RATIO),\n",
        "    '--n-frames', str(N_FRAMES),\n",
        "    '--batch-size', str(BATCH_SIZE),\n",
        "    '--num-workers', str(NUM_WORKERS),\n",
        "    '--generator-norm', str(GENERATOR_NORM),\n",
        "    '--generator-spectral-norm' if GENERATOR_SPECTRAL_NORM else '',\n",
        "    '--generator-upsample', str(GENERATOR_UPSAMPLE),\n",
        "    '--discriminator-arch', str(DISCRIMINATOR_ARCH),\n",
        "    '--discriminator-scales', str(DISCRIMINATOR_SCALES),\n",
        "    '--stage1-epochs', str(STAGE1_EPOCHS),\n",
        "    '--stage2-epochs', str(STAGE2_EPOCHS),\n",
        "    '--lr-g', str(LR_G),\n",
        "    '--lr-d', str(LR_D),\n",
        "    '--adv-weight', str(ADV_WEIGHT),\n",
        "    '--recon-weight', str(RECON_WEIGHT),\n",
        "    '--content-weight', str(CONTENT_WEIGHT),\n",
        "    '--style-weight', str(STYLE_WEIGHT),\n",
        "    '--continuity-weight', str(CONTINUITY_WEIGHT),\n",
        "    '--mrstft-weight', str(MRSTFT_WEIGHT),\n",
        "    '--stage1-mrstft-weight', str(STAGE1_MRSTFT_WEIGHT),\n",
        "    '--stage2-mrstft-weight', str(STAGE2_MRSTFT_WEIGHT),\n",
        "    '--mrstft-resolutions', str(MRSTFT_RESOLUTIONS),\n",
        "    '--flatness-weight', str(FLATNESS_WEIGHT),\n",
        "    '--feature-match-weight', str(FEATURE_MATCH_WEIGHT),\n",
        "    '--perceptual-weight', str(PERCEPTUAL_WEIGHT),\n",
        "    '--style-hinge-weight', str(STYLE_HINGE_WEIGHT),\n",
        "    '--contrastive-weight', str(CONTRASTIVE_WEIGHT),\n",
        "    '--batch-infonce-div-weight', str(BATCH_INFONCE_DIV_WEIGHT),\n",
        "    '--diversity-weight', str(DIVERSITY_WEIGHT),\n",
        "    '--timbre-balance-weight', str(TIMBRE_BALANCE_WEIGHT),\n",
        "    '--lowmid-recon-weight', str(LOWMID_RECON_WEIGHT),\n",
        "    '--spectral-tilt-weight', str(SPECTRAL_TILT_WEIGHT),\n",
        "    '--zcr-proxy-weight', str(ZCR_PROXY_WEIGHT),\n",
        "    '--style-mid-weight', str(STYLE_MID_WEIGHT),\n",
        "    '--hf-muzzle-weight', str(HF_MUZZLE_WEIGHT),\n",
        "    '--highpass-anchor-weight', str(HIGHPASS_ANCHOR_WEIGHT),\n",
        "    '--mel-diversity-weight', str(MEL_DIVERSITY_WEIGHT),\n",
        "    '--target-profile-weight', str(TARGET_PROFILE_WEIGHT),\n",
        "    '--stage2-d-lr-mult', str(STAGE2_D_LR_MULT),\n",
        "    '--stage2-content-start', str(STAGE2_CONTENT_START),\n",
        "    '--stage2-content-end', str(STAGE2_CONTENT_END),\n",
        "    '--stage2-style-label-smoothing', str(STAGE2_STYLE_LABEL_SMOOTHING),\n",
        "    '--stage2-style-only-warmup-epochs', str(STAGE2_STYLE_ONLY_WARMUP_EPOCHS),\n",
        "    '--stage2-g-lr-warmup-epochs', str(STAGE2_G_LR_WARMUP_EPOCHS),\n",
        "    '--stage2-g-lr-start-mult', str(STAGE2_G_LR_START_MULT),\n",
        "    '--stage2-cond-noise-std', str(STAGE2_COND_NOISE_STD),\n",
        "    '--stage2-cond-mode', str(STAGE2_COND_MODE),\n",
        "    '--stage2-cond-alpha-start', str(STAGE2_COND_ALPHA_START),\n",
        "    '--stage2-cond-alpha-end', str(STAGE2_COND_ALPHA_END),\n",
        "    '--stage2-cond-exemplar-noise-std', str(STAGE2_COND_EXEMPLAR_NOISE_STD),\n",
        "    '--stage2-target-balance' if STAGE2_TARGET_BALANCE else '--no-stage2-target-balance',\n",
        "    '--stage2-style-jitter-std', str(STAGE2_STYLE_JITTER_STD),\n",
        "    '--stage2-style-hinge-target-conf', str(STAGE2_STYLE_HINGE_TARGET_CONF),\n",
        "    '--stage2-adaptive-content-low', str(STAGE2_ADAPTIVE_CONTENT_LOW),\n",
        "    '--stage2-adaptive-content-high', str(STAGE2_ADAPTIVE_CONTENT_HIGH),\n",
        "    '--stage2-adaptive-conf-low', str(STAGE2_ADAPTIVE_CONF_LOW),\n",
        "    '--stage2-adaptive-conf-high', str(STAGE2_ADAPTIVE_CONF_HIGH),\n",
        "    '--stage2-style-critic-lr', str(STAGE2_STYLE_CRITIC_LR),\n",
        "    '--stage2-contrastive-temp', str(STAGE2_CONTRASTIVE_TEMP),\n",
        "    '--stage2-batch-infonce-temp', str(STAGE2_BATCH_INFONCE_TEMP),\n",
        "    '--stage2-diversity-margin', str(STAGE2_DIVERSITY_MARGIN),\n",
        "    '--stage2-diversity-max-pairs', str(STAGE2_DIVERSITY_MAX_PAIRS),\n",
        "    '--stage2-mel-diversity-margin', str(STAGE2_MEL_DIVERSITY_MARGIN),\n",
        "    '--stage2-mel-diversity-max-pairs', str(STAGE2_MEL_DIVERSITY_MAX_PAIRS),\n",
        "    '--stage2-style-lowpass-keep-bins', str(STAGE2_STYLE_LOWPASS_KEEP_BINS),\n",
        "    '--stage2-style-lowpass-cutoff-hz', str(STAGE2_STYLE_LOWPASS_CUTOFF_HZ),\n",
        "    '--stage2-style-mid-low-bin', str(STAGE2_STYLE_MID_LOW_BIN),\n",
        "    '--stage2-style-mid-high-bin', str(STAGE2_STYLE_MID_HIGH_BIN),\n",
        "    '--stage2-lowmid-split-bin', str(STAGE2_LOWMID_SPLIT_BIN),\n",
        "    '--stage2-lowmid-gain', str(STAGE2_LOWMID_GAIN),\n",
        "    '--stage2-high-gain', str(STAGE2_HIGH_GAIN),\n",
        "    '--stage2-spectral-tilt-max-ratio', str(STAGE2_SPECTRAL_TILT_MAX_RATIO),\n",
        "    '--stage2-zcr-proxy-target-max', str(STAGE2_ZCR_PROXY_TARGET_MAX),\n",
        "    '--stage2-style-thaw-last-epochs', str(STAGE2_STYLE_THAW_LAST_EPOCHS),\n",
        "    '--stage2-style-thaw-lr', str(STAGE2_STYLE_THAW_LR),\n",
        "    '--stage2-style-thaw-scope', str(STAGE2_STYLE_THAW_SCOPE),\n",
        "    '--mps-threshold', str(MPS_THRESHOLD),\n",
        "    '--sf-threshold', str(SF_THRESHOLD),\n",
        "    '--eval-max-batches', str(EVAL_MAX_BATCHES),\n",
        "    '--auto-sample-export',\n",
        "    '--sample-count', str(POSTTRAIN_SAMPLE_COUNT),\n",
        "    '--sample-target-mode', str(POSTTRAIN_SAMPLE_TARGET_MODE),\n",
        "    '--sample-griffin-lim-iters', str(GL_ITERS),\n",
        "    '--sample-export-tag', str(POSTTRAIN_SAMPLE_EXPORT_TAG),\n",
        "    '--sample-write-real-audio' if POSTTRAIN_SAMPLE_WRITE_REAL else '--no-sample-write-real-audio',\n",
        "    '--device', str(DEVICE),\n",
        "    '--d-real-label', str(D_REAL_LABEL),\n",
        "    '--d-fake-label', str(D_FAKE_LABEL),\n",
        "    '--g-real-label', str(G_REAL_LABEL),\n",
        "]\n",
        "if RUN_MODE == 'fresh':\n",
        "    cmd.extend(['--run-name', RUN_NAME])\n",
        "if RUN_MODE == 'resume':\n",
        "    cmd.extend(['--resume-dir', str(OUT_DIR)])\n",
        "if REUSE_CACHE_DIR is not None:\n",
        "    cmd.extend(['--reuse-cache-dir', str(REUSE_CACHE_DIR)])\n",
        "if MAX_BATCHES_PER_EPOCH is not None:\n",
        "    cmd.extend(['--max-batches-per-epoch', str(MAX_BATCHES_PER_EPOCH)])\n",
        "if SMOKE:\n",
        "    cmd.append('--smoke')\n",
        "if STAGE2_ADAPTIVE_CONTENT:\n",
        "    cmd.append('--stage2-adaptive-content')\n",
        "if RESET_STAGE2_OUT_LAYER:\n",
        "    cmd.append('--reset-stage2-out-layer')\n",
        "cmd = [x for x in cmd if x != '' ]\n",
        "print(' '.join(cmd))\n",
        "# Stream training logs directly to notebook output\n",
        "p = subprocess.Popen(\n",
        "    cmd,\n",
        "    cwd=str(LAB3_DIR),\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True,\n",
        "    bufsize=1,\n",
        ")\n",
        "for line in p.stdout:\n",
        "    print(line, end='')\n",
        "ret = p.wait()\n",
        "if ret != 0:\n",
        "    raise subprocess.CalledProcessError(ret, cmd)\n",
        "# In fresh auto-run mode, resolve OUT_DIR to the created runN folder.\n",
        "if RUN_MODE == 'fresh' and RUN_NAME == '':\n",
        "    latest = find_latest_run_dir(SAVES_ROOT)\n",
        "    if latest is None:\n",
        "        raise FileNotFoundError('No run directory with run_state.json found under SAVES_ROOT after training.')\n",
        "    OUT_DIR = latest\n",
        "    print(f'[post-run] resolved run_dir = {OUT_DIR}')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb6c55df",
      "metadata": {},
      "source": [
        "## Load Run Outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3f4ef05",
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 38) (50314973.py, line 38)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint('\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 38)\n"
          ]
        }
      ],
      "source": [
        "def resolve_run_dir_for_metrics(out_dir: Path, saves_root: Path, resume_dir: Path | None = None) -> Path:\n",
        "    if (out_dir / 'run_state.json').exists():\n",
        "        return out_dir\n",
        "\n",
        "    if resume_dir is not None:\n",
        "        resume_path = Path(resume_dir)\n",
        "        if (resume_path / 'run_state.json').exists():\n",
        "            return resume_path\n",
        "\n",
        "    latest = find_latest_run_dir(saves_root)\n",
        "    if latest is not None:\n",
        "        print(f'[metrics] OUT_DIR has no run_state.json, using latest run dir: {latest}')\n",
        "        return latest\n",
        "\n",
        "    raise FileNotFoundError(\n",
        "        f\"No run_state.json found. Checked OUT_DIR={out_dir} and no run dirs under {saves_root}.\"\n",
        "    )\n",
        "\n",
        "OUT_DIR = resolve_run_dir_for_metrics(OUT_DIR, SAVES_ROOT, RESUME_DIR if RUN_MODE == 'resume' else None)\n",
        "run_state_path = OUT_DIR / 'run_state.json'\n",
        "audit_path = OUT_DIR / 'lab3_exit_audit.json'\n",
        "history_path = OUT_DIR / 'history.csv'\n",
        "\n",
        "run_state = json.loads(run_state_path.read_text(encoding='utf-8'))\n",
        "audit = json.loads(audit_path.read_text(encoding='utf-8')) if audit_path.exists() else {}\n",
        "history = pd.read_csv(history_path) if history_path.exists() else pd.DataFrame()\n",
        "\n",
        "print('[resolved_out_dir]', OUT_DIR)\n",
        "print('[run_state]')\n",
        "print(json.dumps({\n",
        "    'stage_cache_done': run_state.get('stage_cache_done'),\n",
        "    'stage1_done': run_state.get('stage1_done'),\n",
        "    'stage2_done': run_state.get('stage2_done'),\n",
        "    'eval_done': run_state.get('eval_done'),\n",
        "    'lab3_done': run_state.get('lab3_done'),\n",
        "}, indent=2))\n",
        "\n",
        "print('[audit]')\n",
        "print(json.dumps(audit, indent=2))\n",
        "\n",
        "history.tail(10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5054d45",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional quick training curves\n",
        "if len(history):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    for stg, g in history.groupby('stage'):\n",
        "        axes[0].plot(g['epoch'], g['loss_g'], marker='o', label=stg)\n",
        "        axes[1].plot(g['epoch'], g['loss_d'], marker='o', label=stg)\n",
        "    axes[0].set_title('Generator Loss')\n",
        "    axes[1].set_title('Discriminator Loss')\n",
        "    for ax in axes:\n",
        "        ax.set_xlabel('Epoch')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0fd7ffe",
      "metadata": {},
      "source": [
        "## Generation Samples (Direct Results)\n",
        "\n",
        "This cell loads the trained Stage 2 checkpoint and creates side-by-side outputs:\n",
        "- real mel / generated mel plots\n",
        "- reconstructed WAVs from mel via Griffin-Lim\n",
        "- a summary CSV with source/target genres and quick content similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8467ee5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Post-train sample export using the shared CLI helper\n",
        "cache_dir = OUT_DIR / 'cache'\n",
        "idx_df, arrays, genre_to_idx = load_cache(cache_dir)\n",
        "run_state_path = OUT_DIR / 'run_state.json'\n",
        "run_cfg = json.loads(run_state_path.read_text(encoding='utf-8')) if run_state_path.exists() else {}\n",
        "run_cfg = run_cfg.get('config', {}) if isinstance(run_cfg, dict) else {}\n",
        "\n",
        "lab1_ckpt_for_samples = Path(run_cfg.get('lab1_checkpoint', str(LAB1_CHECKPOINT)))\n",
        "lab2_centroids_for_samples = Path(run_cfg.get('lab2_centroids_json', str(LAB2_TARGET_CENTROIDS)))\n",
        "g_norm = str(run_cfg.get('generator_norm', globals().get('GENERATOR_NORM', 'instance')))\n",
        "g_upsample = str(run_cfg.get('generator_upsample', globals().get('GENERATOR_UPSAMPLE', 'transpose')))\n",
        "g_sn = bool(run_cfg.get('generator_spectral_norm', globals().get('GENERATOR_SPECTRAL_NORM', False)))\n",
        "g_mrf = bool(run_cfg.get('generator_mrf', False))\n",
        "g_mrf_kernels = tuple(int(x.strip()) for x in str(run_cfg.get('generator_mrf_kernels', '3,7,11')).split(',') if x.strip())\n",
        "\n",
        "device_t = 'cuda' if (DEVICE == 'auto' and torch.cuda.is_available()) else DEVICE\n",
        "if device_t == 'auto':\n",
        "    device_t = 'cpu'\n",
        "\n",
        "encoder = FrozenLab1Encoder(lab1_ckpt_for_samples, device=device_t)\n",
        "centroids = load_target_centroids(lab2_centroids_for_samples)\n",
        "cond_bank = build_condition_bank(genre_to_idx, centroids).to(device_t)\n",
        "\n",
        "G = ReconstructionDecoder(\n",
        "    zc_dim=arrays['z_content'].shape[1],\n",
        "    cond_dim=cond_bank.shape[1],\n",
        "    n_mels=arrays['mel_norm'].shape[1],\n",
        "    n_frames=arrays['mel_norm'].shape[2],\n",
        "    norm=g_norm,\n",
        "    upsample=g_upsample,\n",
        "    spectral_norm=g_sn,\n",
        "    mrf=g_mrf,\n",
        "    mrf_kernels=g_mrf_kernels,\n",
        ").to(device_t)\n",
        "ckpt = torch.load(OUT_DIR / 'checkpoints' / 'stage2_latest.pt', map_location='cpu')\n",
        "incoming = ckpt.get('generator', {})\n",
        "current = G.state_dict()\n",
        "filtered = {k: v for k, v in incoming.items() if (k in current and tuple(v.shape) == tuple(current[k].shape))}\n",
        "G.load_state_dict(filtered, strict=False)\n",
        "G.eval()\n",
        "\n",
        "train_idx, val_idx = stratified_split_indices(arrays['genre_idx'], val_ratio=VAL_RATIO, seed=SEED)\n",
        "if len(val_idx) == 0:\n",
        "    val_idx = np.arange(min(POSTTRAIN_SAMPLE_COUNT, len(arrays['genre_idx'])))\n",
        "\n",
        "source_map = {}\n",
        "rs = json.loads(run_state_path.read_text(encoding='utf-8')) if run_state_path.exists() else {}\n",
        "if isinstance(rs, dict):\n",
        "    source_map = rs.get('genre_to_lab1_source_idx', {}) or {}\n",
        "\n",
        "sample_out = OUT_DIR / 'samples' / POSTTRAIN_SAMPLE_EXPORT_TAG\n",
        "sample_info = export_posttrain_samples(\n",
        "    generator=G,\n",
        "    frozen_encoder=encoder,\n",
        "    arrays=arrays,\n",
        "    index_df=idx_df,\n",
        "    genre_to_idx=genre_to_idx,\n",
        "    cond_bank=cond_bank,\n",
        "    out_dir=sample_out,\n",
        "    val_idx=val_idx,\n",
        "    n_samples=int(POSTTRAIN_SAMPLE_COUNT),\n",
        "    target_mode=str(POSTTRAIN_SAMPLE_TARGET_MODE),\n",
        "    griffin_lim_iters=int(GL_ITERS),\n",
        "    seed=int(SEED),\n",
        "    device=device_t,\n",
        "    genre_to_source_idx={str(g): int(v) for g, v in source_map.items()} if isinstance(source_map, dict) else None,\n",
        "    write_real_audio=bool(POSTTRAIN_SAMPLE_WRITE_REAL),\n",
        ")\n",
        "print('[sample-export]', sample_info)\n",
        "samples_df = pd.read_csv(sample_out / 'generation_summary.csv')\n",
        "samples_df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a20f05e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview first generated sample inline (if WAV exists)\n",
        "summary_csv = OUT_DIR / 'samples' / POSTTRAIN_SAMPLE_EXPORT_TAG / 'generation_summary.csv'\n",
        "if summary_csv.exists():\n",
        "    gen = pd.read_csv(summary_csv)\n",
        "    if len(gen):\n",
        "        cols = [c for c in ['source_genre', 'target_genre', 'mps_cosine'] if c in gen.columns]\n",
        "        print(gen.iloc[0][cols])\n",
        "        fake_wav = gen.iloc[0]['fake_wav']\n",
        "        real_wav = gen.iloc[0]['real_wav']\n",
        "        if isinstance(real_wav, str) and len(real_wav) and Path(real_wav).exists():\n",
        "            print('Real preview:')\n",
        "            display(Audio(filename=real_wav))\n",
        "        if isinstance(fake_wav, str) and len(fake_wav) and Path(fake_wav).exists():\n",
        "            print('Generated preview:')\n",
        "            display(Audio(filename=fake_wav))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3869aab",
      "metadata": {},
      "source": [
        "## Notes\n",
        "\n",
        "- If style fidelity remains low in early runs, that is expected for short training.\n",
        "- Use resume mode to continue training from the same run folder.\n",
        "- Generation audio uses Griffin-Lim from mel and is only for qualitative sanity checks.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}