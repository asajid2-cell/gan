{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29a58003",
   "metadata": {},
   "source": [
    "# Lab 3 - Architecture 4.0 Symmetry-Balanced Pipeline\n",
    "\n",
    "This notebook runs the three-phase research pipeline (Grounding -> Adversarial Polish -> Style Thaw) with full save/resume and sample generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd3c355",
   "metadata": {},
   "source": [
    "## Architecture 4.0 Plan\n",
    "\n",
    "| Phase | Epochs | Objective | Primary losses |\n",
    "|---|---:|---|---|\n",
    "| I: Spectral Grounding | 10 | Lock structure + phase consistency | `MRSTFT` + `Mel-L1` |\n",
    "| II: Adversarial Polish | 30 | Improve realism + style texture | `Hinge GAN` + `Hybrid critic (MSD+MPD)` + feature matching |\n",
    "| III: Style Thaw | 10 | Close generated/real style domain gap | style-head thaw + label smoothing + contrastive diversity |\n",
    "\n",
    "This notebook keeps the same QoL workflow as before: run naming, resume mode, cache reuse, checkpoints, audit JSON/CSV, and generation snippets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fa67b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import soundfile as sf\n",
    "    HAS_SF = True\n",
    "except Exception:\n",
    "    HAS_SF = False\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "from src.lab3_data import load_cache, stratified_split_indices\n",
    "from src.lab3_models import ReconstructionDecoder\n",
    "from src.lab3_bridge import FrozenLab1Encoder, denormalize_log_mel\n",
    "from src.lab3_train import load_target_centroids, build_condition_bank\n",
    "import importlib\n",
    "\n",
    "# torch sanity guard for notebook kernels with partially initialized modules\n",
    "if not hasattr(torch, '_utils'):\n",
    "    torch._utils = importlib.import_module('torch._utils')\n",
    "print('torch:', torch.__version__, 'file:', torch.__file__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc4a15d",
   "metadata": {},
   "source": [
    "## Run Config\n",
    "\n",
    "Set everything here, then run all cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfe62f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Core run controls\n",
    "# -----------------------------\n",
    "REPO_ROOT = Path.cwd().parent\n",
    "LAB3_DIR = Path.cwd()\n",
    "SAVES_ROOT = REPO_ROOT / 'saves' / 'lab3_synthesis'\n",
    "\n",
    "def find_latest_run_dir(saves_root: Path):\n",
    "    candidates = []\n",
    "    for d in saves_root.iterdir() if saves_root.exists() else []:\n",
    "        if not d.is_dir():\n",
    "            continue\n",
    "        rs = d / 'run_state.json'\n",
    "        if rs.exists():\n",
    "            candidates.append(d)\n",
    "    if not candidates:\n",
    "        return None\n",
    "    return max(candidates, key=lambda p: (p / 'run_state.json').stat().st_mtime)\n",
    "\n",
    "RUN_MODE = 'fresh'         # 'fresh' or 'resume'\n",
    "RUN_NAME = 'automatedruns23'  # set '' for auto run_N\n",
    "RESUME_DIR = SAVES_ROOT / 'automatedruns20'  # best current architecture run\n",
    "CLEAN_START = False          # if fresh and run folder exists, delete it first\n",
    "\n",
    "# Optional cache reuse (speeds up iteration)\n",
    "REUSE_CACHE_DIR = None  # resume from run cache/checkpoints\n",
    "\n",
    "# -----------------------------\n",
    "# Data/model paths\n",
    "# -----------------------------\n",
    "MANIFESTS_ROOT = Path('Z:/DataSets/_lab1_manifests')\n",
    "LAB1_CHECKPOINT = REPO_ROOT / 'saves' / 'lab1_run_combo_af_gate_exit_v2' / 'latest.pt'\n",
    "LAB2_TARGET_CENTROIDS = REPO_ROOT / 'saves' / 'lab2_calibration' / 'lab2_20260211_015118_lda_cleanup_v2' / 'target_centroids.json'\n",
    "\n",
    "# -----------------------------\n",
    "# Training scale\n",
    "# -----------------------------\n",
    "SMOKE = False\n",
    "PER_GENRE_SAMPLES = 800\n",
    "VAL_RATIO = 0.15\n",
    "N_FRAMES = 256\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0\n",
    "SEED = 328\n",
    "DEVICE = 'auto'              # 'auto' | 'cuda' | 'cpu'\n",
    "GENERATOR_NORM = 'instance'  # 'instance' | 'batch'\n",
    "GENERATOR_SPECTRAL_NORM = False\n",
    "GENERATOR_MRF = True\n",
    "GENERATOR_MRF_KERNELS = '3,7,11'\n",
    "GENERATOR_UPSAMPLE = 'pixelshuffle'  # 'transpose' | 'pixelshuffle' | 'nearest'\n",
    "DISCRIMINATOR_ARCH = 'hybrid'   # 'single' | 'multiscale' | 'subband' | 'multiperiod' | 'hybrid'\n",
    "DISCRIMINATOR_SCALES = 3\n",
    "DISCRIMINATOR_PERIODS = '1,2,3,5'\n",
    "DISCRIMINATOR_SPECTRAL_NORM = True\n",
    "\n",
    "STAGE1_EPOCHS = 10\n",
    "STAGE2_EPOCHS = 50\n",
    "MAX_BATCHES_PER_EPOCH = None # int or None\n",
    "\n",
    "# -----------------------------\n",
    "# Loss weights\n",
    "# -----------------------------\n",
    "LR_G = 2e-4\n",
    "LR_D = 5e-5\n",
    "GAN_LOSS = 'hinge'\n",
    "R1_GAMMA = 10.0\n",
    "R1_INTERVAL = 16\n",
    "ADV_WEIGHT = 0.8\n",
    "RECON_WEIGHT = 5.0\n",
    "CONTENT_WEIGHT = 3.0\n",
    "STYLE_WEIGHT = 10.0\n",
    "CONTINUITY_WEIGHT = 1.0\n",
    "MRSTFT_WEIGHT = 0.0\n",
    "STAGE1_MRSTFT_WEIGHT = 2.0\n",
    "STAGE2_MRSTFT_WEIGHT = 0.5\n",
    "MRSTFT_RESOLUTIONS = '64,16,64;128,32,128;256,64,256'\n",
    "FLATNESS_WEIGHT = 0.2\n",
    "FEATURE_MATCH_WEIGHT = 1.0\n",
    "PERCEPTUAL_WEIGHT = 0.7\n",
    "STYLE_HINGE_WEIGHT = 3.0\n",
    "CONTRASTIVE_WEIGHT = 5.0\n",
    "BATCH_INFONCE_DIV_WEIGHT = 3.0\n",
    "DIVERSITY_WEIGHT = 2.0\n",
    "TIMBRE_BALANCE_WEIGHT = 2.5\n",
    "LOWMID_RECON_WEIGHT = 1.5\n",
    "SPECTRAL_TILT_WEIGHT = 2.6\n",
    "ZCR_PROXY_WEIGHT = 0.8\n",
    "STYLE_MID_WEIGHT = 3.0\n",
    "HF_MUZZLE_WEIGHT = 2.2\n",
    "HIGHPASS_ANCHOR_WEIGHT = 0.6\n",
    "MEL_DIVERSITY_WEIGHT = 5.0\n",
    "TARGET_PROFILE_WEIGHT = 24.0\n",
    "STAGE2_D_LR_MULT = 1.0\n",
    "STAGE2_CONTENT_START = 0.15\n",
    "STAGE2_CONTENT_END = 0.15\n",
    "STAGE2_STYLE_LABEL_SMOOTHING = 0.1\n",
    "STAGE2_STYLE_ONLY_WARMUP_EPOCHS = 0\n",
    "STAGE2_G_LR_WARMUP_EPOCHS = 0\n",
    "STAGE2_G_LR_START_MULT = 1.0\n",
    "STAGE2_COND_NOISE_STD = 0.10\n",
    "STAGE2_STYLE_JITTER_STD = 0.10\n",
    "STAGE2_STYLE_HINGE_TARGET_CONF = 0.85\n",
    "STAGE2_ADAPTIVE_CONTENT = False\n",
    "STAGE2_ADAPTIVE_CONTENT_LOW = 0.0\n",
    "STAGE2_ADAPTIVE_CONTENT_HIGH = 0.4\n",
    "STAGE2_ADAPTIVE_CONF_LOW = 0.30\n",
    "STAGE2_ADAPTIVE_CONF_HIGH = 0.45\n",
    "STAGE2_STYLE_CRITIC_LR = 2e-4\n",
    "STAGE2_CONTRASTIVE_TEMP = 0.10\n",
    "STAGE2_BATCH_INFONCE_TEMP = 0.15\n",
    "STAGE2_DIVERSITY_MARGIN = 0.90\n",
    "STAGE2_DIVERSITY_MAX_PAIRS = 128\n",
    "STAGE2_MEL_DIVERSITY_MARGIN = 0.60\n",
    "STAGE2_MEL_DIVERSITY_MAX_PAIRS = 192\n",
    "STAGE2_STYLE_LOWPASS_KEEP_BINS = 80\n",
    "STAGE2_STYLE_LOWPASS_CUTOFF_HZ = 4300.0\n",
    "STAGE2_STYLE_MID_LOW_BIN = 8\n",
    "STAGE2_STYLE_MID_HIGH_BIN = 56\n",
    "STAGE2_LOWMID_SPLIT_BIN = 80\n",
    "STAGE2_LOWMID_GAIN = 7.0\n",
    "STAGE2_HIGH_GAIN = 0.45\n",
    "STAGE2_SPECTRAL_TILT_MAX_RATIO = 0.78\n",
    "STAGE2_ZCR_PROXY_TARGET_MAX = 0.20\n",
    "STAGE2_STYLE_THAW_LAST_EPOCHS = 10\n",
    "STAGE2_STYLE_THAW_LR = 1e-6\n",
    "STAGE2_STYLE_THAW_SCOPE = 'style_head'\n",
    "RESET_STAGE2_OUT_LAYER = False\n",
    "D_REAL_LABEL = 0.7\n",
    "D_FAKE_LABEL = 0.3\n",
    "G_REAL_LABEL = 0.7\n",
    "\n",
    "# -----------------------------\n",
    "# Exit thresholds\n",
    "# -----------------------------\n",
    "MPS_THRESHOLD = 0.90\n",
    "SF_THRESHOLD = 0.85\n",
    "EVAL_MAX_BATCHES = 30\n",
    "\n",
    "# -----------------------------\n",
    "# Generation preview settings\n",
    "# -----------------------------\n",
    "N_GENERATION_SAMPLES = 6\n",
    "TARGET_GENRE_ORDER = ['baroque_classical', 'hiphop_xtc', 'lofi_hh_lfbb', 'cc0_other']\n",
    "GL_ITERS = 64\n",
    "\n",
    "if RUN_MODE == 'fresh':\n",
    "    OUT_DIR = SAVES_ROOT / RUN_NAME if RUN_NAME else SAVES_ROOT\n",
    "elif RUN_MODE == 'resume':\n",
    "    if RESUME_DIR is None:\n",
    "        raise ValueError(\"RUN_MODE='resume' requires RESUME_DIR\")\n",
    "    OUT_DIR = Path(RESUME_DIR)\n",
    "else:\n",
    "    raise ValueError(\"RUN_MODE must be 'fresh' or 'resume'\")\n",
    "\n",
    "OUT_DIR\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b04309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare run directory (fresh mode cleanup)\n",
    "if RUN_MODE == 'fresh' and RUN_NAME == '':\n",
    "    print('[setup] RUN_NAME empty: training will auto-create numbered run directories (run_1, run_2, ...).')\n",
    "\n",
    "if RUN_MODE == 'fresh' and CLEAN_START and RUN_NAME and OUT_DIR.exists():\n",
    "    print(f'[setup] removing existing run dir: {OUT_DIR}')\n",
    "    shutil.rmtree(OUT_DIR)\n",
    "\n",
    "if RUN_MODE == 'resume':\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('[setup] target run_dir =', OUT_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab200a58",
   "metadata": {},
   "source": [
    "## Launch Training Pipeline\n",
    "\n",
    "This calls `run_lab3.py` with the config above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd78882",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = [\n",
    "    'python', 'run_lab3.py',\n",
    "    '--mode', RUN_MODE,\n",
    "    '--manifests-root', str(MANIFESTS_ROOT),\n",
    "    '--lab1-checkpoint', str(LAB1_CHECKPOINT),\n",
    "    '--lab2-centroids-json', str(LAB2_TARGET_CENTROIDS),\n",
    "    '--per-genre-samples', str(PER_GENRE_SAMPLES),\n",
    "    '--seed', str(SEED),\n",
    "    '--val-ratio', str(VAL_RATIO),\n",
    "    '--n-frames', str(N_FRAMES),\n",
    "    '--batch-size', str(BATCH_SIZE),\n",
    "    '--num-workers', str(NUM_WORKERS),\n",
    "    '--generator-norm', str(GENERATOR_NORM),\n",
    "    '--generator-spectral-norm' if GENERATOR_SPECTRAL_NORM else '',\n",
    "    '--generator-mrf' if GENERATOR_MRF else '',\n",
    "    '--generator-mrf-kernels', str(GENERATOR_MRF_KERNELS),\n",
    "    '--generator-upsample', str(GENERATOR_UPSAMPLE),\n",
    "    '--discriminator-arch', str(DISCRIMINATOR_ARCH),\n",
    "    '--discriminator-scales', str(DISCRIMINATOR_SCALES),\n",
    "    '--discriminator-periods', str(DISCRIMINATOR_PERIODS),\n",
    "    '--discriminator-spectral-norm' if DISCRIMINATOR_SPECTRAL_NORM else '',\n",
    "    '--stage1-epochs', str(STAGE1_EPOCHS),\n",
    "    '--stage2-epochs', str(STAGE2_EPOCHS),\n",
    "    '--lr-g', str(LR_G),\n",
    "    '--lr-d', str(LR_D),\n",
    "    '--gan-loss', str(GAN_LOSS),\n",
    "    '--r1-gamma', str(R1_GAMMA),\n",
    "    '--r1-interval', str(R1_INTERVAL),\n",
    "    '--adv-weight', str(ADV_WEIGHT),\n",
    "    '--recon-weight', str(RECON_WEIGHT),\n",
    "    '--content-weight', str(CONTENT_WEIGHT),\n",
    "    '--style-weight', str(STYLE_WEIGHT),\n",
    "    '--continuity-weight', str(CONTINUITY_WEIGHT),\n",
    "    '--mrstft-weight', str(MRSTFT_WEIGHT),\n",
    "    '--stage1-mrstft-weight', str(STAGE1_MRSTFT_WEIGHT),\n",
    "    '--stage2-mrstft-weight', str(STAGE2_MRSTFT_WEIGHT),\n",
    "    '--mrstft-resolutions', str(MRSTFT_RESOLUTIONS),\n",
    "    '--flatness-weight', str(FLATNESS_WEIGHT),\n",
    "    '--feature-match-weight', str(FEATURE_MATCH_WEIGHT),\n",
    "    '--perceptual-weight', str(PERCEPTUAL_WEIGHT),\n",
    "    '--style-hinge-weight', str(STYLE_HINGE_WEIGHT),\n",
    "    '--contrastive-weight', str(CONTRASTIVE_WEIGHT),\n",
    "    '--batch-infonce-div-weight', str(BATCH_INFONCE_DIV_WEIGHT),\n",
    "    '--diversity-weight', str(DIVERSITY_WEIGHT),\n",
    "    '--timbre-balance-weight', str(TIMBRE_BALANCE_WEIGHT),\n",
    "    '--lowmid-recon-weight', str(LOWMID_RECON_WEIGHT),\n",
    "    '--spectral-tilt-weight', str(SPECTRAL_TILT_WEIGHT),\n",
    "    '--zcr-proxy-weight', str(ZCR_PROXY_WEIGHT),\n",
    "    '--style-mid-weight', str(STYLE_MID_WEIGHT),\n",
    "    '--hf-muzzle-weight', str(HF_MUZZLE_WEIGHT),\n",
    "    '--highpass-anchor-weight', str(HIGHPASS_ANCHOR_WEIGHT),\n",
    "    '--mel-diversity-weight', str(MEL_DIVERSITY_WEIGHT),\n",
    "    '--target-profile-weight', str(TARGET_PROFILE_WEIGHT),\n",
    "    '--stage2-d-lr-mult', str(STAGE2_D_LR_MULT),\n",
    "    '--stage2-content-start', str(STAGE2_CONTENT_START),\n",
    "    '--stage2-content-end', str(STAGE2_CONTENT_END),\n",
    "    '--stage2-style-label-smoothing', str(STAGE2_STYLE_LABEL_SMOOTHING),\n",
    "    '--stage2-style-only-warmup-epochs', str(STAGE2_STYLE_ONLY_WARMUP_EPOCHS),\n",
    "    '--stage2-g-lr-warmup-epochs', str(STAGE2_G_LR_WARMUP_EPOCHS),\n",
    "    '--stage2-g-lr-start-mult', str(STAGE2_G_LR_START_MULT),\n",
    "    '--stage2-cond-noise-std', str(STAGE2_COND_NOISE_STD),\n",
    "    '--stage2-style-jitter-std', str(STAGE2_STYLE_JITTER_STD),\n",
    "    '--stage2-style-hinge-target-conf', str(STAGE2_STYLE_HINGE_TARGET_CONF),\n",
    "    '--stage2-adaptive-content-low', str(STAGE2_ADAPTIVE_CONTENT_LOW),\n",
    "    '--stage2-adaptive-content-high', str(STAGE2_ADAPTIVE_CONTENT_HIGH),\n",
    "    '--stage2-adaptive-conf-low', str(STAGE2_ADAPTIVE_CONF_LOW),\n",
    "    '--stage2-adaptive-conf-high', str(STAGE2_ADAPTIVE_CONF_HIGH),\n",
    "    '--stage2-style-critic-lr', str(STAGE2_STYLE_CRITIC_LR),\n",
    "    '--stage2-contrastive-temp', str(STAGE2_CONTRASTIVE_TEMP),\n",
    "    '--stage2-batch-infonce-temp', str(STAGE2_BATCH_INFONCE_TEMP),\n",
    "    '--stage2-diversity-margin', str(STAGE2_DIVERSITY_MARGIN),\n",
    "    '--stage2-diversity-max-pairs', str(STAGE2_DIVERSITY_MAX_PAIRS),\n",
    "    '--stage2-mel-diversity-margin', str(STAGE2_MEL_DIVERSITY_MARGIN),\n",
    "    '--stage2-mel-diversity-max-pairs', str(STAGE2_MEL_DIVERSITY_MAX_PAIRS),\n",
    "    '--stage2-style-lowpass-keep-bins', str(STAGE2_STYLE_LOWPASS_KEEP_BINS),\n",
    "    '--stage2-style-lowpass-cutoff-hz', str(STAGE2_STYLE_LOWPASS_CUTOFF_HZ),\n",
    "    '--stage2-style-mid-low-bin', str(STAGE2_STYLE_MID_LOW_BIN),\n",
    "    '--stage2-style-mid-high-bin', str(STAGE2_STYLE_MID_HIGH_BIN),\n",
    "    '--stage2-lowmid-split-bin', str(STAGE2_LOWMID_SPLIT_BIN),\n",
    "    '--stage2-lowmid-gain', str(STAGE2_LOWMID_GAIN),\n",
    "    '--stage2-high-gain', str(STAGE2_HIGH_GAIN),\n",
    "    '--stage2-spectral-tilt-max-ratio', str(STAGE2_SPECTRAL_TILT_MAX_RATIO),\n",
    "    '--stage2-zcr-proxy-target-max', str(STAGE2_ZCR_PROXY_TARGET_MAX),\n",
    "    '--stage2-style-thaw-last-epochs', str(STAGE2_STYLE_THAW_LAST_EPOCHS),\n",
    "    '--stage2-style-thaw-lr', str(STAGE2_STYLE_THAW_LR),\n",
    "    '--stage2-style-thaw-scope', str(STAGE2_STYLE_THAW_SCOPE),\n",
    "    '--mps-threshold', str(MPS_THRESHOLD),\n",
    "    '--sf-threshold', str(SF_THRESHOLD),\n",
    "    '--eval-max-batches', str(EVAL_MAX_BATCHES),\n",
    "    '--device', str(DEVICE),\n",
    "    '--d-real-label', str(D_REAL_LABEL),\n",
    "    '--d-fake-label', str(D_FAKE_LABEL),\n",
    "    '--g-real-label', str(G_REAL_LABEL),\n",
    "]\n",
    "if RUN_MODE == 'fresh':\n",
    "    cmd.extend(['--run-name', RUN_NAME])\n",
    "if RUN_MODE == 'resume':\n",
    "    cmd.extend(['--resume-dir', str(OUT_DIR)])\n",
    "if REUSE_CACHE_DIR is not None:\n",
    "    cmd.extend(['--reuse-cache-dir', str(REUSE_CACHE_DIR)])\n",
    "if MAX_BATCHES_PER_EPOCH is not None:\n",
    "    cmd.extend(['--max-batches-per-epoch', str(MAX_BATCHES_PER_EPOCH)])\n",
    "if SMOKE:\n",
    "    cmd.append('--smoke')\n",
    "if STAGE2_ADAPTIVE_CONTENT:\n",
    "    cmd.append('--stage2-adaptive-content')\n",
    "if RESET_STAGE2_OUT_LAYER:\n",
    "    cmd.append('--reset-stage2-out-layer')\n",
    "cmd = [x for x in cmd if x != '' ]\n",
    "print(' '.join(cmd))\n",
    "# Stream training logs directly to notebook output\n",
    "p = subprocess.Popen(\n",
    "    cmd,\n",
    "    cwd=str(LAB3_DIR),\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    text=True,\n",
    "    bufsize=1,\n",
    ")\n",
    "for line in p.stdout:\n",
    "    print(line, end='')\n",
    "ret = p.wait()\n",
    "if ret != 0:\n",
    "    raise subprocess.CalledProcessError(ret, cmd)\n",
    "# In fresh auto-run mode, resolve OUT_DIR to the created run_N folder.\n",
    "if RUN_MODE == 'fresh' and RUN_NAME == '':\n",
    "    latest = find_latest_run_dir(SAVES_ROOT)\n",
    "    if latest is None:\n",
    "        raise FileNotFoundError('No run directory with run_state.json found under SAVES_ROOT after training.')\n",
    "    OUT_DIR = latest\n",
    "    print(f'[post-run] resolved run_dir = {OUT_DIR}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6c55df",
   "metadata": {},
   "source": [
    "## Load Run Outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f4ef05",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 38) (50314973.py, line 38)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint('\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 38)\n"
     ]
    }
   ],
   "source": [
    "def resolve_run_dir_for_metrics(out_dir: Path, saves_root: Path, resume_dir: Path | None = None) -> Path:\n",
    "    if (out_dir / 'run_state.json').exists():\n",
    "        return out_dir\n",
    "\n",
    "    if resume_dir is not None:\n",
    "        resume_path = Path(resume_dir)\n",
    "        if (resume_path / 'run_state.json').exists():\n",
    "            return resume_path\n",
    "\n",
    "    latest = find_latest_run_dir(saves_root)\n",
    "    if latest is not None:\n",
    "        print(f'[metrics] OUT_DIR has no run_state.json, using latest run dir: {latest}')\n",
    "        return latest\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "        f\"No run_state.json found. Checked OUT_DIR={out_dir} and no run dirs under {saves_root}.\"\n",
    "    )\n",
    "\n",
    "OUT_DIR = resolve_run_dir_for_metrics(OUT_DIR, SAVES_ROOT, RESUME_DIR if RUN_MODE == 'resume' else None)\n",
    "run_state_path = OUT_DIR / 'run_state.json'\n",
    "audit_path = OUT_DIR / 'lab3_exit_audit.json'\n",
    "history_path = OUT_DIR / 'history.csv'\n",
    "\n",
    "run_state = json.loads(run_state_path.read_text(encoding='utf-8'))\n",
    "audit = json.loads(audit_path.read_text(encoding='utf-8')) if audit_path.exists() else {}\n",
    "history = pd.read_csv(history_path) if history_path.exists() else pd.DataFrame()\n",
    "\n",
    "print('[resolved_out_dir]', OUT_DIR)\n",
    "print('[run_state]')\n",
    "print(json.dumps({\n",
    "    'stage_cache_done': run_state.get('stage_cache_done'),\n",
    "    'stage1_done': run_state.get('stage1_done'),\n",
    "    'stage2_done': run_state.get('stage2_done'),\n",
    "    'eval_done': run_state.get('eval_done'),\n",
    "    'lab3_done': run_state.get('lab3_done'),\n",
    "}, indent=2))\n",
    "\n",
    "print('[audit]')\n",
    "print(json.dumps(audit, indent=2))\n",
    "\n",
    "history.tail(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5054d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional quick training curves\n",
    "if len(history):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    for stg, g in history.groupby('stage'):\n",
    "        axes[0].plot(g['epoch'], g['loss_g'], marker='o', label=stg)\n",
    "        axes[1].plot(g['epoch'], g['loss_d'], marker='o', label=stg)\n",
    "    axes[0].set_title('Generator Loss')\n",
    "    axes[1].set_title('Discriminator Loss')\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fd7ffe",
   "metadata": {},
   "source": [
    "## Generation Samples (Direct Results)\n",
    "\n",
    "This cell loads the trained Stage 2 checkpoint and creates side-by-side outputs:\n",
    "- real mel / generated mel plots\n",
    "- reconstructed WAVs from mel via Griffin-Lim\n",
    "- a summary CSV with source/target genres and quick content similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8467ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cache and run config\n",
    "cache_dir = OUT_DIR / 'cache'\n",
    "idx_df, arrays, genre_to_idx = load_cache(cache_dir)\n",
    "idx_to_genre = {v: k for k, v in genre_to_idx.items()}\n",
    "\n",
    "run_state_path = OUT_DIR / 'run_state.json'\n",
    "run_cfg = {}\n",
    "if run_state_path.exists():\n",
    "    try:\n",
    "        run_state_obj = json.loads(run_state_path.read_text(encoding='utf-8'))\n",
    "        run_cfg = run_state_obj.get('config', {}) if isinstance(run_state_obj, dict) else {}\n",
    "    except Exception:\n",
    "        run_cfg = {}\n",
    "\n",
    "lab1_ckpt_for_samples = Path(run_cfg.get('lab1_checkpoint', str(LAB1_CHECKPOINT)))\n",
    "lab2_centroids_for_samples = Path(run_cfg.get('lab2_centroids_json', str(LAB2_TARGET_CENTROIDS)))\n",
    "\n",
    "g_norm = str(run_cfg.get('generator_norm', globals().get('GENERATOR_NORM', 'instance')))\n",
    "g_upsample = str(run_cfg.get('generator_upsample', globals().get('GENERATOR_UPSAMPLE', 'transpose')))\n",
    "\n",
    "encoder = FrozenLab1Encoder(lab1_ckpt_for_samples, device=DEVICE)\n",
    "sr = int(encoder.cfg.sample_rate)\n",
    "\n",
    "centroids = load_target_centroids(lab2_centroids_for_samples)\n",
    "cond_bank = build_condition_bank(genre_to_idx, centroids)\n",
    "\n",
    "print(f\"[sample-load] generator_norm={g_norm} generator_upsample={g_upsample}\")\n",
    "print(f\"[sample-load] lab1_ckpt={lab1_ckpt_for_samples}\")\n",
    "print(f\"[sample-load] lab2_centroids={lab2_centroids_for_samples}\")\n",
    "\n",
    "G = ReconstructionDecoder(\n",
    "    zc_dim=arrays['z_content'].shape[1],\n",
    "    cond_dim=cond_bank.shape[1],\n",
    "    n_mels=arrays['mel_norm'].shape[1],\n",
    "    n_frames=arrays['mel_norm'].shape[2],\n",
    "    norm=g_norm,\n",
    "    upsample=g_upsample,\n",
    ")\n",
    "ckpt = torch.load(OUT_DIR / 'checkpoints' / 'stage2_latest.pt', map_location='cpu')\n",
    "try:\n",
    "    G.load_state_dict(ckpt['generator'], strict=False)\n",
    "except RuntimeError as e:\n",
    "    # Fallback for cross-architecture checkpoint previews (e.g., transpose <-> pixelshuffle).\n",
    "    current = G.state_dict()\n",
    "    incoming = ckpt['generator']\n",
    "    filtered = {k: v for k, v in incoming.items() if (k in current and tuple(v.shape) == tuple(current[k].shape))}\n",
    "    dropped = [k for k, v in incoming.items() if (k not in current or tuple(v.shape) != tuple(current.get(k, v).shape))]\n",
    "    missing, unexpected = G.load_state_dict(filtered, strict=False)\n",
    "    print(f\"[sample-load] partial checkpoint load due to shape mismatch: kept={len(filtered)} dropped={len(dropped)}\")\n",
    "    if dropped:\n",
    "        print('[sample-load] dropped keys (first 8):', dropped[:8])\n",
    "    if missing:\n",
    "        print('[sample-load] missing keys (first 8):', missing[:8])\n",
    "    if unexpected:\n",
    "        print('[sample-load] unexpected keys (first 8):', unexpected[:8])\n",
    "G.eval()\n",
    "\n",
    "device_t = 'cuda' if (DEVICE == 'auto' and torch.cuda.is_available()) else DEVICE\n",
    "if device_t == 'auto':\n",
    "    device_t = 'cpu'\n",
    "G = G.to(device_t)\n",
    "cond_bank = cond_bank.to(device_t)\n",
    "\n",
    "train_idx, val_idx = stratified_split_indices(arrays['genre_idx'], val_ratio=VAL_RATIO, seed=SEED)\n",
    "if len(val_idx) == 0:\n",
    "    val_idx = np.arange(min(N_GENERATION_SAMPLES, len(idx_df)))\n",
    "\n",
    "sample_out = OUT_DIR / 'samples'\n",
    "sample_out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "records = []\n",
    "\n",
    "# helper\n",
    "MEL_DB_MIN = -80.0\n",
    "MEL_DB_MAX = 0.0\n",
    "\n",
    "def mel_norm_to_db_np(m):\n",
    "    t = torch.from_numpy(m).unsqueeze(0)\n",
    "    db = denormalize_log_mel(t).squeeze(0).cpu().numpy()\n",
    "    return db\n",
    "\n",
    "def mel_db_to_audio(mel_db):\n",
    "    mel_power = librosa.db_to_power(mel_db)\n",
    "    y = librosa.feature.inverse.mel_to_audio(\n",
    "        mel_power,\n",
    "        sr=sr,\n",
    "        n_fft=1024,\n",
    "        hop_length=256,\n",
    "        win_length=1024,\n",
    "        fmin=20,\n",
    "        fmax=sr//2,\n",
    "        n_iter=GL_ITERS,\n",
    "    )\n",
    "    if np.max(np.abs(y)) > 0:\n",
    "        y = y / (np.max(np.abs(y)) + 1e-8)\n",
    "    return y.astype(np.float32)\n",
    "\n",
    "chosen = val_idx[: min(N_GENERATION_SAMPLES, len(val_idx))]\n",
    "\n",
    "for j, ridx in enumerate(chosen):\n",
    "    src_genre_idx = int(arrays['genre_idx'][ridx])\n",
    "    src_genre = idx_to_genre[src_genre_idx]\n",
    "\n",
    "    # pick target genre by rotating list; enforce different genre when possible\n",
    "    tgt_name = TARGET_GENRE_ORDER[j % len(TARGET_GENRE_ORDER)]\n",
    "    if tgt_name == src_genre:\n",
    "        tgt_name = TARGET_GENRE_ORDER[(j + 1) % len(TARGET_GENRE_ORDER)]\n",
    "    if tgt_name not in genre_to_idx:\n",
    "        tgt_name = list(genre_to_idx.keys())[(src_genre_idx + 1) % len(genre_to_idx)]\n",
    "    tgt_idx = int(genre_to_idx[tgt_name])\n",
    "\n",
    "    zc = torch.from_numpy(arrays['z_content'][ridx]).unsqueeze(0).to(device_t).float()\n",
    "    cond = cond_bank[tgt_idx].unsqueeze(0).float()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fake_norm = G(zc, cond).squeeze(0).cpu().numpy().astype(np.float32)\n",
    "\n",
    "    real_norm = arrays['mel_norm'][ridx].astype(np.float32)\n",
    "    fake_db = mel_norm_to_db_np(fake_norm)\n",
    "    real_db = mel_norm_to_db_np(real_norm)\n",
    "\n",
    "    # quick content preservation check on generated sample\n",
    "    with torch.no_grad():\n",
    "        out_fake = encoder.forward_log_mel_tensor(torch.from_numpy(fake_db).unsqueeze(0).to(encoder.device).float())\n",
    "    zc_fake = out_fake['z_content'][0].detach().cpu().numpy()\n",
    "    zc_src = arrays['z_content'][ridx]\n",
    "    mps = float(np.dot(zc_fake / (np.linalg.norm(zc_fake)+1e-8), zc_src / (np.linalg.norm(zc_src)+1e-8)))\n",
    "\n",
    "    # save mel comparison figure\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 4), constrained_layout=True)\n",
    "    ax[0].imshow(real_db, aspect='auto', origin='lower', cmap='magma')\n",
    "    ax[0].set_title(f'Real ({src_genre})')\n",
    "    ax[1].imshow(fake_db, aspect='auto', origin='lower', cmap='magma')\n",
    "    ax[1].set_title(f'Generated -> {tgt_name}')\n",
    "    for a in ax:\n",
    "        a.set_xlabel('Frame')\n",
    "        a.set_ylabel('Mel Bin')\n",
    "    fig_path = sample_out / f'sample_{j:02d}_mel.png'\n",
    "    fig.savefig(fig_path, dpi=160)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # save audio previews (if soundfile available)\n",
    "    real_wav = sample_out / f'sample_{j:02d}_real.wav'\n",
    "    fake_wav = sample_out / f'sample_{j:02d}_fake_to_{tgt_name}.wav'\n",
    "    if HAS_SF:\n",
    "        y_real = mel_db_to_audio(real_db)\n",
    "        y_fake = mel_db_to_audio(fake_db)\n",
    "        sf.write(str(real_wav), y_real, sr)\n",
    "        sf.write(str(fake_wav), y_fake, sr)\n",
    "    else:\n",
    "        real_wav = None\n",
    "        fake_wav = None\n",
    "\n",
    "    records.append({\n",
    "        'sample_id': int(ridx),\n",
    "        'path': idx_df.iloc[ridx]['path'],\n",
    "        'source_genre': src_genre,\n",
    "        'target_genre': tgt_name,\n",
    "        'mps_cosine': mps,\n",
    "        'mel_plot': str(fig_path),\n",
    "        'real_wav': '' if real_wav is None else str(real_wav),\n",
    "        'fake_wav': '' if fake_wav is None else str(fake_wav),\n",
    "    })\n",
    "\n",
    "samples_df = pd.DataFrame(records)\n",
    "samples_df.to_csv(sample_out / 'generation_summary.csv', index=False)\n",
    "samples_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview first generated sample inline (if WAV exists)\n",
    "summary_csv = OUT_DIR / 'samples' / 'generation_summary.csv'\n",
    "if summary_csv.exists():\n",
    "    gen = pd.read_csv(summary_csv)\n",
    "    if len(gen):\n",
    "        print(gen.iloc[0][['source_genre', 'target_genre', 'mps_cosine']])\n",
    "        fake_wav = gen.iloc[0]['fake_wav']\n",
    "        real_wav = gen.iloc[0]['real_wav']\n",
    "        if isinstance(real_wav, str) and len(real_wav) and Path(real_wav).exists():\n",
    "            print('Real preview:')\n",
    "            display(Audio(filename=real_wav))\n",
    "        if isinstance(fake_wav, str) and len(fake_wav) and Path(fake_wav).exists():\n",
    "            print('Generated preview:')\n",
    "            display(Audio(filename=fake_wav))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3869aab",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- If style fidelity remains low in early runs, that is expected for short training.\n",
    "- Use resume mode to continue training from the same run folder.\n",
    "- Generation audio uses Griffin-Lim from mel and is only for qualitative sanity checks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
