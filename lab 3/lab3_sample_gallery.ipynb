{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Lab 3 Sample Gallery (Codec + Mel)\n\nThis notebook is now codec-aware and defaults to the codec run path.\n\nUse it to:\n- load an existing run (`lab3_codec_transfer` or `lab3_synthesis`)\n- optionally generate fresh samples from checkpoint\n- listen to **source chunk vs generated** side-by-side\n- compare quick similarity metrics (wave cosine / MFCC cosine)."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from pathlib import Path\nimport sys\nimport json\nimport random\nimport importlib\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport librosa\nimport matplotlib.pyplot as plt\n\ntry:\n    import soundfile as sf\n    HAS_SF = True\nexcept Exception:\n    HAS_SF = False\n\nfrom IPython.display import Audio, display\n\ncwd = Path.cwd()\nif (cwd / 'src').exists() and ((cwd / 'run_lab3.py').exists() or (cwd / 'run_lab3_codec.py').exists()):\n    LAB3_DIR = cwd\n    REPO_ROOT = cwd.parent\nelif (cwd / 'lab 3' / 'src').exists():\n    LAB3_DIR = cwd / 'lab 3'\n    REPO_ROOT = cwd\nelse:\n    raise RuntimeError('Run from repo root or lab 3 directory.')\n\nif str(LAB3_DIR) not in sys.path:\n    sys.path.insert(0, str(LAB3_DIR))\n\nif not hasattr(torch, '_utils'):\n    torch._utils = importlib.import_module('torch._utils')\n\nimport subprocess\nimport importlib.util\n\ndef _ensure_pkg(mod_name: str, pip_name: str | None = None):\n    if importlib.util.find_spec(mod_name) is None:\n        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pip_name or mod_name])\n\n_ensure_pkg('transformers')\n_ensure_pkg('sentencepiece')\n\nfrom src.lab3_data import load_cache, stratified_split_indices, stratified_group_split_indices\nfrom src.lab3_codec_data import load_codec_cache\nfrom src.lab3_codec_models import CodecLatentTranslator\nfrom src.lab3_codec_bridge import FrozenEncodec\nfrom src.lab3_codec_train import build_style_centroid_bank, build_style_exemplar_bank\nfrom src.lab3_sampling import resolve_next_run_name\n\nprint('torch:', torch.__version__)\nprint('soundfile_available:', HAS_SF)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Config"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Defaults now target codec pipeline run1005\nRUN_KIND = 'codec'   # 'codec' | 'mel' | 'auto'\n\nCODEC_RUNS_ROOT = REPO_ROOT / 'saves2' / 'lab3_codec_transfer'\nMEL_RUNS_ROOT = REPO_ROOT / 'saves2' / 'lab3_synthesis'\n\nRUN_DIR = CODEC_RUNS_ROOT / 'run1005'  # set None to auto-pick latest runN in selected root\nOUTPUT_TAG = 'posttrain_samples'\n\nGENERATE_NEW_SAMPLES = False\nFORCE_REGENERATE = False\nN_GENERATION_SAMPLES = 50\nVAL_RATIO = 0.15\nSEED = 328\n\nCODEC_COND_MODE = 'mix'   # centroid | exemplar | mix\nCODEC_COND_ALPHA = 0.35\nCODEC_STYLE_JITTER_STD = 0.03\n\nPREVIEW_RANDOM = True\nPREVIEW_N = 8\nEXPORT_SOURCE_PAIRS = True\n\nDEVICE = 'auto'\n\ndef _latest_run(root: Path):\n    if not root.exists():\n        return None\n    cands = []\n    for d in root.iterdir():\n        if d.is_dir() and d.name.startswith('run') and d.name[3:].isdigit() and (d / 'run_state.json').exists():\n            cands.append((int(d.name[3:]), d))\n    if not cands:\n        return None\n    cands.sort(key=lambda x: x[0])\n    return cands[-1][1]"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "if RUN_DIR is None:\n    root = CODEC_RUNS_ROOT if RUN_KIND in ('codec', 'auto') else MEL_RUNS_ROOT\n    RUN_DIR = _latest_run(root)\n\nif RUN_DIR is None or not RUN_DIR.exists():\n    raise FileNotFoundError(f'RUN_DIR not found: {RUN_DIR}')\n\nrun_state_path = RUN_DIR / 'run_state.json'\nif not run_state_path.exists():\n    raise FileNotFoundError(run_state_path)\n\nrun_state = json.loads(run_state_path.read_text(encoding='utf-8'))\ncfg = run_state.get('config', {}) if isinstance(run_state, dict) else {}\n\nif RUN_KIND == 'auto':\n    if (RUN_DIR / 'cache' / 'codec_cache_arrays.npz').exists() and (RUN_DIR / 'checkpoints' / 'stage3_latest.pt').exists():\n        run_kind = 'codec'\n    else:\n        run_kind = 'mel'\nelse:\n    run_kind = RUN_KIND\n\nprint('RUN_DIR:', RUN_DIR)\nprint('run_kind:', run_kind)\nprint('run_name:', run_state.get('run_name', RUN_DIR.name))"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "rng = np.random.default_rng(int(SEED))\nif DEVICE == 'auto':\n    device_t = 'cuda' if torch.cuda.is_available() else 'cpu'\nelse:\n    device_t = DEVICE\n\nsamples_dir = RUN_DIR / 'samples' / OUTPUT_TAG\nsamples_dir.mkdir(parents=True, exist_ok=True)\nsummary_csv = samples_dir / 'generation_summary.csv'\n\nif run_kind != 'codec':\n    raise RuntimeError('This notebook is now intended for codec runs. Set RUN_KIND=codec or auto with codec run dir.')\n\n# Load codec cache\ncache_dir = RUN_DIR / 'cache'\nidx_df, arrays, genre_to_idx, cache_meta = load_codec_cache(cache_dir)\nn_genres = len(genre_to_idx)\nidx_to_genre = {int(v): str(k) for k, v in genre_to_idx.items()}\n\n# Build train/val split for sampling\nif 'track_id' in idx_df.columns and bool(cfg.get('split_by_track', True)):\n    train_idx, val_idx = stratified_group_split_indices(\n        arrays['genre_idx'],\n        idx_df['track_id'].astype(str).to_numpy(),\n        val_ratio=float(cfg.get('val_ratio', VAL_RATIO)),\n        seed=int(cfg.get('seed', SEED)),\n    )\nelse:\n    train_idx, val_idx = stratified_split_indices(\n        arrays['genre_idx'],\n        val_ratio=float(cfg.get('val_ratio', VAL_RATIO)),\n        seed=int(cfg.get('seed', SEED)),\n    )\n\nstyle_centroid_bank = build_style_centroid_bank(arrays['z_style'], arrays['genre_idx'], n_genres=n_genres).to(device_t)\nstyle_exemplar_bank = build_style_exemplar_bank(arrays['z_style'][train_idx], arrays['genre_idx'][train_idx], n_genres=n_genres)\n\n# Load codec model + checkpoint\ncodec = FrozenEncodec(\n    model_id=str(cfg.get('codec_model_id', 'facebook/encodec_24khz')),\n    bandwidth=float(cfg.get('codec_bandwidth', 6.0)),\n    chunk_seconds=float(cfg.get('codec_chunk_seconds', 5.0)),\n    device=device_t,\n)\n\nG = CodecLatentTranslator(\n    in_channels=int(arrays['q_emb'].shape[1]),\n    z_content_dim=int(arrays['z_content'].shape[1]),\n    z_style_dim=int(arrays['z_style'].shape[1]),\n    hidden_channels=int(cfg.get('translator_hidden_channels', 256)),\n    n_blocks=int(cfg.get('translator_blocks', 10)),\n    noise_dim=int(cfg.get('translator_noise_dim', 32)),\n    residual_scale=float(cfg.get('translator_residual_scale', 0.5)),\n).to(device_t)\n\nckpt_candidates = [RUN_DIR / 'checkpoints' / 'stage3_latest.pt', RUN_DIR / 'checkpoints' / 'stage2_latest.pt', RUN_DIR / 'checkpoints' / 'stage1_latest.pt']\nckpt_path = next((p for p in ckpt_candidates if p.exists()), None)\nif ckpt_path is None:\n    raise FileNotFoundError('No stage checkpoint found in run checkpoints/')\n\ntry:\n    payload = torch.load(str(ckpt_path), map_location='cpu', weights_only=False)\nexcept TypeError:\n    payload = torch.load(str(ckpt_path), map_location='cpu')\nG.load_state_dict(payload['generator'], strict=True)\nG.eval()\n\nprint('Loaded checkpoint:', ckpt_path.name)\nprint('cache rows:', len(idx_df), 'val rows:', len(val_idx), 'genres:', genre_to_idx)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def _pick_target(src_g: int, n_genres: int, i: int) -> int:\n    # balanced random-like by cycling + anti-clash\n    tgt = int((i + src_g + 1) % n_genres)\n    if tgt == int(src_g):\n        tgt = int((tgt + 1) % n_genres)\n    return tgt\n\ndef _z_tgt_for_genre(tgt_g: int):\n    z_cent = style_centroid_bank[tgt_g:tgt_g+1].to(device_t).float()\n    ex_bank = style_exemplar_bank.get(int(tgt_g))\n    if ex_bank is None or int(ex_bank.shape[0]) == 0:\n        z_ex = z_cent\n    else:\n        j = int(rng.integers(0, int(ex_bank.shape[0])))\n        z_ex = ex_bank[j:j+1].to(device_t).float()\n    if CODEC_COND_MODE == 'centroid':\n        z = z_cent\n    elif CODEC_COND_MODE == 'exemplar':\n        z = z_ex\n    else:\n        z = float(CODEC_COND_ALPHA) * z_cent + (1.0 - float(CODEC_COND_ALPHA)) * z_ex\n    if float(CODEC_STYLE_JITTER_STD) > 0.0:\n        z = z + torch.randn_like(z) * float(CODEC_STYLE_JITTER_STD)\n    return torch.nn.functional.normalize(z, dim=-1)\n\nif (GENERATE_NEW_SAMPLES and (FORCE_REGENERATE or (not summary_csv.exists()))):\n    rows = []\n    for i in range(int(N_GENERATION_SAMPLES)):\n        ridx = int(val_idx[int(rng.integers(0, len(val_idx)))])\n        src_g = int(arrays['genre_idx'][ridx])\n        tgt_g = _pick_target(src_g, n_genres=n_genres, i=i)\n\n        q_src = torch.from_numpy(arrays['q_emb'][ridx:ridx+1]).to(device_t).float()\n        zc = torch.from_numpy(arrays['z_content'][ridx:ridx+1]).to(device_t).float()\n        z_tgt = _z_tgt_for_genre(tgt_g)\n\n        with torch.no_grad():\n            q_hat = G(q_src=q_src, z_content=zc, z_style_tgt=z_tgt)\n            wav = codec.decode_embeddings(q_hat)[0, 0].detach().cpu().numpy().astype(np.float32)\n        wav = wav / (np.max(np.abs(wav)) + 1e-8)\n\n        out_wav = samples_dir / f'sample_{i:04d}_src{src_g}_tgt{tgt_g}.wav'\n        sf.write(str(out_wav), wav, int(codec.cfg.sample_rate))\n\n        rows.append({\n            'sample_id': int(i),\n            'cache_row': int(ridx),\n            'source_genre_idx': int(src_g),\n            'target_genre_idx': int(tgt_g),\n            'source_genre': idx_to_genre.get(int(src_g), str(src_g)),\n            'target_genre': idx_to_genre.get(int(tgt_g), str(tgt_g)),\n            'fake_wav': str(out_wav),\n        })\n\n    pd.DataFrame(rows).to_csv(summary_csv, index=False)\n    print('Generated samples ->', summary_csv)\nelse:\n    print('Using existing sample summary:', summary_csv)\n\nif not summary_csv.exists():\n    raise FileNotFoundError(f'Missing generation summary: {summary_csv}')"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "df = pd.read_csv(summary_csv)\nif 'source_genre' not in df.columns and 'source_genre_idx' in df.columns:\n    df['source_genre'] = df['source_genre_idx'].map(lambda x: idx_to_genre.get(int(x), str(x)))\nif 'target_genre' not in df.columns and 'target_genre_idx' in df.columns:\n    df['target_genre'] = df['target_genre_idx'].map(lambda x: idx_to_genre.get(int(x), str(x)))\n\npair_dir = samples_dir / 'source_pairs'\npair_dir.mkdir(parents=True, exist_ok=True)\n\nchunk_seconds = float(cfg.get('codec_chunk_seconds', 5.0))\nsr = int(codec.cfg.sample_rate)\n\nsrc_wavs = []\nwave_cos = []\nmfcc_cos = []\n\nfor _, r in df.iterrows():\n    ridx = int(r['cache_row'])\n    fake_path = Path(r['fake_wav'])\n    meta = idx_df.iloc[ridx]\n    src_path = Path(str(meta['path']))\n    start_sec = float(meta.get('start_sec', 0.0))\n\n    y_src, _ = librosa.load(str(src_path), sr=sr, mono=True, offset=max(0.0, start_sec), duration=max(0.2, chunk_seconds))\n    y_fake, _ = librosa.load(str(fake_path), sr=sr, mono=True)\n    n = min(len(y_src), len(y_fake))\n    if n <= 1:\n        src_wavs.append('')\n        wave_cos.append(np.nan)\n        mfcc_cos.append(np.nan)\n        continue\n\n    y_src = y_src[:n].astype(np.float32)\n    y_fake = y_fake[:n].astype(np.float32)\n\n    src_out = pair_dir / f\"sample_{int(r['sample_id']):04d}_source.wav\"\n    if EXPORT_SOURCE_PAIRS:\n        sf.write(str(src_out), y_src, sr)\n        src_wavs.append(str(src_out))\n    else:\n        src_wavs.append('')\n\n    c = float(np.dot(y_src, y_fake) / ((np.linalg.norm(y_src) * np.linalg.norm(y_fake)) + 1e-12))\n    wave_cos.append(c)\n\n    m1 = librosa.feature.mfcc(y=y_src, sr=sr, n_mfcc=13).mean(axis=1)\n    m2 = librosa.feature.mfcc(y=y_fake, sr=sr, n_mfcc=13).mean(axis=1)\n    mcos = float(np.dot(m1, m2) / ((np.linalg.norm(m1) * np.linalg.norm(m2)) + 1e-12))\n    mfcc_cos.append(mcos)\n\ndf['source_wav'] = src_wavs\ndf['wave_cosine_src_fake'] = wave_cos\ndf['mfcc_cosine_src_fake'] = mfcc_cos\n\ncompare_csv = samples_dir / 'generation_compare_with_source.csv'\ndf.to_csv(compare_csv, index=False)\nprint('compare csv:', compare_csv)\nprint('rows:', len(df))\ndisplay(df[['sample_id','source_genre','target_genre','wave_cosine_src_fake','mfcc_cosine_src_fake']].head(12))"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "print('Mean wave cosine (src vs fake):', float(df['wave_cosine_src_fake'].mean()))\nprint('Mean MFCC cosine (src vs fake):', float(df['mfcc_cosine_src_fake'].mean()))\n\ndisplay(df.groupby(['source_genre','target_genre']).size().rename('count').reset_index())\ndisplay(df.groupby('target_genre')[['wave_cosine_src_fake','mfcc_cosine_src_fake']].mean().reset_index())"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "view_df = df.copy()\nif PREVIEW_RANDOM:\n    view_df = view_df.sample(min(int(PREVIEW_N), len(view_df)), random_state=int(SEED)).reset_index(drop=True)\nelse:\n    view_df = view_df.head(min(int(PREVIEW_N), len(view_df))).reset_index(drop=True)\n\nfor i, r in view_df.iterrows():\n    sid = int(r['sample_id'])\n    print(f\"[{i}] sample={sid} | {r['source_genre']} -> {r['target_genre']} | wave_cos={r['wave_cosine_src_fake']:.3f} | mfcc_cos={r['mfcc_cosine_src_fake']:.3f}\")\n    src = Path(r['source_wav']) if isinstance(r.get('source_wav',''), str) and len(str(r.get('source_wav',''))) else None\n    fake = Path(r['fake_wav']) if isinstance(r.get('fake_wav',''), str) and len(str(r.get('fake_wav',''))) else None\n\n    if src is not None and src.exists():\n        print('Source chunk:')\n        display(Audio(filename=str(src)))\n    if fake is not None and fake.exists():\n        print('Generated:')\n        display(Audio(filename=str(fake)))\n    print('-' * 70)"
    }
  ]
}