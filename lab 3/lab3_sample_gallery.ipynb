{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 3 Sample Gallery\n",
        "\n",
        "Generate qualitative samples from any Lab 3 run checkpoint.\n",
        "\n",
        "This notebook is configured by default for `automatedruns20`.\n",
        "It exports:\n",
        "- generated WAV files\n",
        "- optional real WAV references\n",
        "- mel comparison plots\n",
        "- `generation_summary.csv`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "import json\n",
        "import random\n",
        "import shutil\n",
        "import importlib\n",
        "\n",
        "# ensure `lab 3/src` is importable whether notebook is run from repo root or lab 3 dir\n",
        "cwd = Path.cwd()\n",
        "if (cwd / 'src').exists() and (cwd / 'run_lab3.py').exists():\n",
        "    sys.path.insert(0, str(cwd))\n",
        "elif (cwd / 'lab 3' / 'src').exists():\n",
        "    sys.path.insert(0, str(cwd / 'lab 3'))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    import soundfile as sf\n",
        "    HAS_SF = True\n",
        "except Exception:\n",
        "    HAS_SF = False\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "from src.lab3_data import load_cache, stratified_split_indices\n",
        "from src.lab3_models import ReconstructionDecoder\n",
        "from src.lab3_bridge import FrozenLab1Encoder, denormalize_log_mel\n",
        "from src.lab3_train import load_target_centroids, build_condition_bank\n",
        "from src.lab3_sampling import export_posttrain_samples\n",
        "\n",
        "if not hasattr(torch, '_utils'):\n",
        "    torch._utils = importlib.import_module('torch._utils')\n",
        "\n",
        "print('torch:', torch.__version__)\n",
        "print('soundfile_available:', HAS_SF)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Config\n",
        "\n",
        "Change `RUN_DIR` to any run under `saves2/lab3_synthesis`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resolve repo root robustly\n",
        "cwd = Path.cwd()\n",
        "if (cwd / 'src').exists() and (cwd / 'run_lab3.py').exists():\n",
        "    LAB3_DIR = cwd\n",
        "    REPO_ROOT = cwd.parent\n",
        "elif (cwd / 'lab 3' / 'src').exists():\n",
        "    LAB3_DIR = cwd / 'lab 3'\n",
        "    REPO_ROOT = cwd\n",
        "else:\n",
        "    raise RuntimeError('Run this notebook from repo root or from lab 3 directory.')\n",
        "\n",
        "SAVES_ROOT = REPO_ROOT / 'saves2' / 'lab3_synthesis'\n",
        "RUN_DIR = None  # set explicit path or keep None to auto-select latest runN\n",
        "CHECKPOINT_NAME = 'stage2_latest.pt'\n",
        "\n",
        "OUTPUT_TAG = 'posttrain_samples'\n",
        "OVERWRITE_OUTPUT = False\n",
        "WRITE_REAL_AUDIO = True\n",
        "\n",
        "N_GENERATION_SAMPLES = 100\n",
        "VAL_RATIO = 0.15\n",
        "SEED = 328\n",
        "\n",
        "TARGET_MODE = 'balanced_random'   # 'balanced_random' | 'round_robin' | 'random'\n",
        "TARGET_GENRE_ORDER = ['hiphop_xtc', 'lofi_hh_lfbb', 'baroque_classical', 'cc0_other']\n",
        "\n",
        "GL_ITERS = 48\n",
        "DEVICE = 'auto'\n",
        "\n",
        "def find_latest_runN(saves_root: Path):\n",
        "    if not saves_root.exists():\n",
        "        return None\n",
        "    cands = []\n",
        "    for d in saves_root.iterdir():\n",
        "        if not d.is_dir():\n",
        "            continue\n",
        "        name = d.name\n",
        "        if name.startswith('run') and name[3:].isdigit() and (d / 'run_state.json').exists():\n",
        "            cands.append((int(name[3:]), d))\n",
        "    if not cands:\n",
        "        return None\n",
        "    cands.sort(key=lambda x: x[0])\n",
        "    return cands[-1][1]\n",
        "\n",
        "if RUN_DIR is None:\n",
        "    latest = find_latest_runN(SAVES_ROOT)\n",
        "    if latest is None:\n",
        "        raise FileNotFoundError(f'No runN folders with run_state.json under {SAVES_ROOT}')\n",
        "    RUN_DIR = latest\n",
        "\n",
        "print('LAB3_DIR:', LAB3_DIR)\n",
        "print('RUN_DIR:', RUN_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run_state_path = RUN_DIR / 'run_state.json'\n",
        "cache_dir = RUN_DIR / 'cache'\n",
        "ckpt_path = RUN_DIR / 'checkpoints' / CHECKPOINT_NAME\n",
        "\n",
        "if not run_state_path.exists():\n",
        "    raise FileNotFoundError(f'Missing run_state.json: {run_state_path}')\n",
        "if not cache_dir.exists():\n",
        "    raise FileNotFoundError(f'Missing cache dir: {cache_dir}')\n",
        "if not ckpt_path.exists():\n",
        "    raise FileNotFoundError(f'Missing checkpoint: {ckpt_path}')\n",
        "\n",
        "run_state = json.loads(run_state_path.read_text(encoding='utf-8'))\n",
        "run_cfg = run_state.get('config', {}) if isinstance(run_state, dict) else {}\n",
        "\n",
        "idx_df, arrays, genre_to_idx = load_cache(cache_dir)\n",
        "idx_to_genre = {v: k for k, v in genre_to_idx.items()}\n",
        "\n",
        "lab1_ckpt = Path(run_cfg.get('lab1_checkpoint', REPO_ROOT / 'saves' / 'lab1_run_combo_af_gate_exit_v2' / 'latest.pt'))\n",
        "lab2_centroids = Path(run_cfg.get('lab2_centroids_json', REPO_ROOT / 'saves' / 'lab2_calibration' / 'target_centroids.json'))\n",
        "\n",
        "g_norm = str(run_cfg.get('generator_norm', 'instance'))\n",
        "g_upsample = str(run_cfg.get('generator_upsample', 'transpose'))\n",
        "g_sn = bool(run_cfg.get('generator_spectral_norm', False))\n",
        "g_mrf = bool(run_cfg.get('generator_mrf', False))\n",
        "g_mrf_kernels = tuple(int(x.strip()) for x in str(run_cfg.get('generator_mrf_kernels', '3,7,11')).split(',') if x.strip())\n",
        "\n",
        "if DEVICE == 'auto':\n",
        "    device_t = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "else:\n",
        "    device_t = DEVICE\n",
        "\n",
        "encoder = FrozenLab1Encoder(lab1_ckpt, device=device_t)\n",
        "sr = int(encoder.cfg.sample_rate)\n",
        "\n",
        "centroids = load_target_centroids(lab2_centroids)\n",
        "cond_bank = build_condition_bank(genre_to_idx, centroids).to(device_t)\n",
        "\n",
        "G = ReconstructionDecoder(\n",
        "    zc_dim=int(arrays['z_content'].shape[1]),\n",
        "    cond_dim=int(cond_bank.shape[1]),\n",
        "    n_mels=int(arrays['mel_norm'].shape[1]),\n",
        "    n_frames=int(arrays['mel_norm'].shape[2]),\n",
        "    norm=g_norm,\n",
        "    upsample=g_upsample,\n",
        "    spectral_norm=g_sn,\n",
        "    mrf=g_mrf,\n",
        "    mrf_kernels=g_mrf_kernels,\n",
        ").to(device_t)\n",
        "\n",
        "payload = torch.load(ckpt_path, map_location='cpu')\n",
        "incoming = payload.get('generator', {})\n",
        "current = G.state_dict()\n",
        "filtered = {k: v for k, v in incoming.items() if (k in current and tuple(v.shape) == tuple(current[k].shape))}\n",
        "missing, unexpected = G.load_state_dict(filtered, strict=False)\n",
        "dropped = [k for k, v in incoming.items() if (k not in current or tuple(v.shape) != tuple(current.get(k, v).shape))]\n",
        "\n",
        "G.eval()\n",
        "\n",
        "print('[load] device:', device_t)\n",
        "print('[load] generator_norm:', g_norm, 'upsample:', g_upsample, 'mrf:', g_mrf, 'sn:', g_sn)\n",
        "print('[load] genres:', list(genre_to_idx.keys()))\n",
        "print('[load] checkpoint keys kept:', len(filtered), 'dropped:', len(dropped))\n",
        "if dropped:\n",
        "    print('[load] dropped keys (first 8):', dropped[:8])\n",
        "\n",
        "train_idx, val_idx = stratified_split_indices(arrays['genre_idx'], val_ratio=VAL_RATIO, seed=SEED)\n",
        "if len(val_idx) == 0:\n",
        "    val_idx = np.arange(len(arrays['genre_idx']))\n",
        "\n",
        "rng = np.random.default_rng(SEED)\n",
        "n_pick = min(int(N_GENERATION_SAMPLES), len(val_idx))\n",
        "picked_idx = rng.choice(val_idx, size=n_pick, replace=False)\n",
        "\n",
        "source_map = run_state.get('genre_to_lab1_source_idx', {}) if isinstance(run_state, dict) else {}\n",
        "print('[load] selected samples:', len(picked_idx))\n",
        "print('[load] source-map available for genres:', source_map)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MEL_DB_MIN = -80.0\n",
        "MEL_DB_MAX = 0.0\n",
        "\n",
        "def mel_norm_to_db_np(mel_norm_np: np.ndarray) -> np.ndarray:\n",
        "    t = torch.from_numpy(mel_norm_np).unsqueeze(0)\n",
        "    db = denormalize_log_mel(t).squeeze(0).cpu().numpy()\n",
        "    return db.astype(np.float32)\n",
        "\n",
        "def mel_db_to_audio(mel_db: np.ndarray, sr: int, gl_iters: int) -> np.ndarray:\n",
        "    mel_power = librosa.db_to_power(mel_db)\n",
        "    y = librosa.feature.inverse.mel_to_audio(\n",
        "        mel_power,\n",
        "        sr=sr,\n",
        "        n_fft=1024,\n",
        "        hop_length=256,\n",
        "        win_length=1024,\n",
        "        fmin=20,\n",
        "        fmax=sr // 2,\n",
        "        n_iter=int(gl_iters),\n",
        "    )\n",
        "    if np.max(np.abs(y)) > 0:\n",
        "        y = y / (np.max(np.abs(y)) + 1e-8)\n",
        "    return y.astype(np.float32)\n",
        "\n",
        "def choose_target_genre(sample_i: int, src_genre: str, all_genres: list[str], rng: np.random.Generator) -> str:\n",
        "    candidates = [g for g in TARGET_GENRE_ORDER if g in all_genres]\n",
        "    if not candidates:\n",
        "        candidates = list(all_genres)\n",
        "\n",
        "    if TARGET_MODE == 'random':\n",
        "        tgt = str(rng.choice(candidates))\n",
        "    else:\n",
        "        tgt = candidates[sample_i % len(candidates)]\n",
        "\n",
        "    if len(candidates) > 1 and tgt == src_genre:\n",
        "        if TARGET_MODE == 'random':\n",
        "            other = [g for g in candidates if g != src_genre]\n",
        "            tgt = str(rng.choice(other))\n",
        "        else:\n",
        "            tgt = candidates[(sample_i + 1) % len(candidates)]\n",
        "    return tgt\n",
        "\n",
        "def cosine_np(a: np.ndarray, b: np.ndarray) -> float:\n",
        "    an = np.linalg.norm(a) + 1e-8\n",
        "    bn = np.linalg.norm(b) + 1e-8\n",
        "    return float(np.dot(a, b) / (an * bn))\n",
        "\n",
        "def style_eval_for_target(fake_db: np.ndarray, target_genre: str) -> tuple[str, float]:\n",
        "    with torch.no_grad():\n",
        "        x = torch.from_numpy(fake_db).unsqueeze(0).to(device_t)\n",
        "        out = encoder.model(x, grl_lambda=0.0)\n",
        "        logits = out['style_logits'][0]\n",
        "        probs = torch.softmax(logits, dim=0).detach().cpu().numpy()\n",
        "\n",
        "    source_idx = int(source_map.get(target_genre, -1)) if isinstance(source_map, dict) else -1\n",
        "    if source_idx >= 0 and source_idx < len(probs):\n",
        "        conf = float(probs[source_idx])\n",
        "    else:\n",
        "        conf = float(np.max(probs))\n",
        "    pred_idx = int(np.argmax(probs))\n",
        "    idx_to_source = {v: k for k, v in encoder.source_to_idx.items()}\n",
        "    pred_name = idx_to_source.get(pred_idx, str(pred_idx))\n",
        "    return pred_name, conf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "export_dir = RUN_DIR / 'samples' / OUTPUT_TAG\n",
        "if OVERWRITE_OUTPUT and export_dir.exists():\n",
        "    shutil.rmtree(export_dir)\n",
        "\n",
        "sample_info = export_posttrain_samples(\n",
        "    generator=G,\n",
        "    frozen_encoder=encoder,\n",
        "    arrays=arrays,\n",
        "    index_df=idx_df,\n",
        "    genre_to_idx=genre_to_idx,\n",
        "    cond_bank=cond_bank,\n",
        "    out_dir=export_dir,\n",
        "    val_idx=val_idx,\n",
        "    n_samples=int(N_GENERATION_SAMPLES),\n",
        "    target_mode=str(TARGET_MODE),\n",
        "    griffin_lim_iters=int(GL_ITERS),\n",
        "    seed=int(SEED),\n",
        "    device=device_t,\n",
        "    genre_to_source_idx={str(g): int(v) for g, v in source_map.items()} if isinstance(source_map, dict) else None,\n",
        "    write_real_audio=bool(WRITE_REAL_AUDIO),\n",
        ")\n",
        "\n",
        "print('[export]', sample_info)\n",
        "summary_csv = Path(sample_info['summary_csv'])\n",
        "samples_df = pd.read_csv(summary_csv)\n",
        "print('[export] rows:', len(samples_df))\n",
        "samples_df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary_csv = RUN_DIR / 'samples' / OUTPUT_TAG / 'generation_summary.csv'\n",
        "if not summary_csv.exists():\n",
        "    raise FileNotFoundError(summary_csv)\n",
        "\n",
        "df = pd.read_csv(summary_csv)\n",
        "print('Rows:', len(df))\n",
        "if len(df):\n",
        "    print('Mean MPS:', float(df['mps_cosine'].mean()))\n",
        "    if 'style_conf_target' in df.columns:\n",
        "        print('Mean style_conf_target:', float(df['style_conf_target'].fillna(0.0).mean()))\n",
        "\n",
        "display(df.groupby(['source_genre', 'target_genre']).size().rename('count').reset_index())\n",
        "display(df.groupby('target_genre')['mps_cosine'].mean().rename('mean_mps').reset_index())\n",
        "if 'style_conf_target' in df.columns:\n",
        "    display(df.groupby('target_genre')['style_conf_target'].mean().rename('mean_style_conf').reset_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary_csv = RUN_DIR / 'samples' / OUTPUT_TAG / 'generation_summary.csv'\n",
        "df = pd.read_csv(summary_csv)\n",
        "preview_n = min(3, len(df))\n",
        "\n",
        "for i in range(preview_n):\n",
        "    r = df.iloc[i]\n",
        "    conf = r['style_conf_target'] if 'style_conf_target' in df.columns else float('nan')\n",
        "    print(f\"[{i}] {r['source_genre']} -> {r['target_genre']} | mps={r['mps_cosine']:.3f} | style_conf={conf:.3f}\")\n",
        "    real_wav = Path(r['real_wav']) if isinstance(r['real_wav'], str) and len(r['real_wav']) else None\n",
        "    fake_wav = Path(r['fake_wav']) if isinstance(r['fake_wav'], str) and len(r['fake_wav']) else None\n",
        "    if real_wav is not None and real_wav.exists():\n",
        "        print('Real:')\n",
        "        display(Audio(filename=str(real_wav)))\n",
        "    if fake_wav is not None and fake_wav.exists():\n",
        "        print('Generated:')\n",
        "        display(Audio(filename=str(fake_wav)))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}